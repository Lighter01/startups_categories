{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef45e873-5a70-468b-9e1b-a601ec78e7c9",
   "metadata": {},
   "source": [
    "# Исследование прогнозирования успеха стартапов с использованием методов науки о данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e6af0-30dd-4664-aedb-c69d0db2a013",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d4234-c24a-496a-9943-e706d384fecc",
   "metadata": {},
   "source": [
    "В современном мире стартапы играют ключевую роль в экономическом развитии, но лишь немногие из них достигают успеха. Для инвесторов и предпринимателей важно понимать, какие факторы влияют на успешность стартапа. В данном исследовании мы обращаемся к методам анализа данных для построения моделей, способных прогнозировать исход предпринимательских начинаний."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9bb59-91bf-484c-b5f9-c21b2f0f5615",
   "metadata": {},
   "source": [
    "## Цель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ecd23-78c3-4a7a-a080-5c237c89d3d2",
   "metadata": {},
   "source": [
    "Целью исследования является применение методов анализа данных для изучения факторов, влияющих на успешность стартапов, а также для создания моделей, способных предсказывать их результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c933cc8-e657-4db3-a291-dd8a301937c5",
   "metadata": {},
   "source": [
    "## План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a6cd1-a3ef-4950-aa11-81280be98cdf",
   "metadata": {},
   "source": [
    "- **Загрузка и ознакомление с данными**: загрузка и изучение наборов данных о стартапах, включая тренировочные и тестовые выборки.\n",
    "\n",
    "- **Предварительная обработка данных**: очистка и подготовка данных для дальнейшего анализа, включая обработку пропущенных значений и выбросов.\n",
    "\n",
    "- **Разведочный анализ**: анализ данных с целью выявить закономерности и тренды, а также для поиска ключевых признаков, влияющих на успешность стартапов.\n",
    "\n",
    "- **Создание новых признаков**: разработка новых признаки на основе имеющихся данных для повышения качества моделей.\n",
    "\n",
    "- **Обучение моделей**: выбор и обучение модели машинного обучения для прогнозирования успешности стартапов.\n",
    "\n",
    "- **Оценка качества моделей**: оценка качества построенных моделей с использованием подходящих метрик и методов валидации.\n",
    "\n",
    "- **Анализ важности признаков**: анализ важности признаков для выявления ключевых факторов, влияющих на результаты предпринимательской деятельности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a9100-9954-4338-947e-551adc10270e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719d9ec-84b0-4ffc-a7c5-f0a207b85f5b",
   "metadata": {},
   "source": [
    "# Подготовка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d710e4-1619-4a4c-bf52-ecdb0b69f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87b3d0-9a4e-48ac-a718-95116f7630cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Lighter01/startups_categories/main/env.yml'\n",
    "\n",
    "yaml_file = './datasets/env.yml'\n",
    "\n",
    "if os.path.exists(yaml_file):\n",
    "    print(\"File already exists.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(yaml_file, 'wb') as json_file:\n",
    "            yaml_file.write(response.content)\n",
    "        print(\"YAML file with environment dependencies downloaded successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download YAML file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53fb4a-a2ff-42ad-951e-73def6fdc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = './datasets/env.yml'\n",
    "\n",
    "os.system(f'conda install --file {yaml_file}')\n",
    "\n",
    "print(\"Packages installed successfully into the current environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85d70c-c03b-4557-bef6-8b87a622b29d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "# import umap\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, SelectKBest\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, TargetEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, StratifiedKFold, StratifiedShuffleSplit, RepeatedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import shap\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "import miceforest as mf\n",
    "from miceforest import mean_match_default\n",
    "# from optuna.samplers.nsgaii import VSBXCrossover\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, metrics, Pool, cv\n",
    "import lightgbm as lgb\n",
    "\n",
    "# from typing import List, Tuple, Dict, Any, Callable, Union\n",
    "# from pandas import DataFrame, Series\n",
    "\n",
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "import json\n",
    "from fuzzywuzzy import fuzz, process\n",
    "# import us\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc80bdb-9651-443f-a3fc-4a7baaa94802",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7aef57-d3d5-46f6-b42b-dbcf80d4510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = px.colors.qualitative.Plotly\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=[i for i in range(0, len(palette))], y=[1] * len(palette), marker_color=palette))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    title=\"Color palette\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac77aec-d950-4670-8306-5d16cc8eb0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './datasets/kaggle_startups_train_01.csv'\n",
    "path2 = './datasets/kaggle_startups_test_01.csv'\n",
    "path3 = './datasets/kaggle_startups_sample_submit_01.csv'\n",
    "\n",
    "def read_file(path):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, sep=',')\n",
    "    else:\n",
    "        print('No such file or directory')\n",
    "    return df\n",
    "\n",
    "df_train   = read_file(path1)\n",
    "df_test    = read_file(path2)\n",
    "df_sampsub = read_file(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b439f-51d4-482f-a82c-1ba1293f5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e49e6-2d4e-4a6c-8074-089ebbd77f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919f35a-df4e-43db-9031-4d49e0d3650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampsub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c5a0a-7e56-41ec-8872-917ad0c3693b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf691ae-db2b-4055-8661-5b8efbb4700e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8a075-db47-4f5b-b175-73ec1e4b181e",
   "metadata": {},
   "source": [
    "# IDA / preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea60af4-fb19-4994-958b-c8ab8e31ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a12b4d-15ca-4b28-b704-f1a06eee9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e652590-14ba-4080-9734-1962c5b4b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampsub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca959107-be21-45d2-816c-86b8904c33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nans(df):\n",
    "    nans_per_col = [(col, df[col].isna().sum(), df[col].isna().sum() / df.shape[0] * 100) for col in df.columns]\n",
    "    dtype = [('col_name', 'U20'), ('nans', int), ('nans_perc', float)]\n",
    "    nans_per_col = np.array(nans_per_col, dtype=dtype)\n",
    "    nans_per_col = nans_per_col[nans_per_col['nans'] > 0]\n",
    "    nans_per_col = np.sort(nans_per_col, order='nans')\n",
    "\n",
    "    df_show = pd.DataFrame(nans_per_col[::-1])\n",
    "    display(df_show.style.background_gradient(cmap='Blues'))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    y_pos = np.arange(len(nans_per_col))\n",
    "    \n",
    "    ax.barh(y_pos, nans_per_col['nans_perc'], alpha=0.8, edgecolor='black', linewidth=1) \n",
    "    ax.set_yticks(y_pos, labels=nans_per_col['col_name'])\n",
    "    ax.set_xlabel('Nans, %', fontsize=14)\n",
    "    ax.set_title('Nans rate for each column', fontsize=16)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "    ax.grid(axis='x', linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72bb23e-cfcd-46c5-8832-93a843de671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nans(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7837ed-a214-45af-b523-25a93f5e42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nans(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc75a4-5dcc-4f61-acfe-73be9d02cb2f",
   "metadata": {},
   "source": [
    "Проверка на полностью пустые строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebaf00c-e4a0-4684-94d1-8b9447f95cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.isna().all(axis=1).sum(), df_test.isna().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73ec52-743a-4c69-a293-fb08617fc731",
   "metadata": {},
   "source": [
    "Проверка на явные дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d7569-6638-444e-a607-efc014e4bce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_train.duplicated(keep=False).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f9ece-f1e0-4216-b28d-b04d7dc3872a",
   "metadata": {},
   "source": [
    "### name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3db93a-a8a5-45a7-b36b-89231c45d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['name'])\n",
    "df_test  = df_test.drop(columns=['name'])\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f568a-5f5b-400b-8fe3-ba6602aa6d43",
   "metadata": {},
   "source": [
    "### founded_at, first_funding_at, last_funding_at, closed_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f544a0-6a42-4232-b3c5-01af09ba592f",
   "metadata": {},
   "source": [
    "Приведем все признаки, содержащие даты, к типу datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7835e18-9ca6-410f-a306-1c2adccf2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_to_datetime(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_datetime(df[column], errors='coerce', format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "df_train = cast_to_datetime(df_train, ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "df_test  = cast_to_datetime(df_test,  ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249cc74e-8c4d-4694-abdc-8c2a203d4990",
   "metadata": {},
   "source": [
    "Проверим даты на соответствие реальности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d992beb-5b6a-4456-ad10-a4e9367536e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_date_range(df, columns):\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=columns)\n",
    "    \n",
    "    for i, column in enumerate(columns, start=1):\n",
    "        row = 1 if i <= 2 else 2\n",
    "        col = i if i <= 2 else i - 2\n",
    "        trace = go.Box(y=df[column].dt.year, name='', showlegend=False)\n",
    "        fig.add_trace(trace, row=row, col=col)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1000,\n",
    "        title='Boxplots of dates by Year'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_date_range(df_train, ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce140749-295c-4836-9ee3-3e54c2461622",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date_range(df_test, ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55d594-9587-4539-922d-6de252b061d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_date_range(df, cols):\n",
    "    for col in cols:\n",
    "        print(col, df[col].min(), df[col].max())\n",
    "\n",
    "print_date_range(df_train, ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "print()\n",
    "print_date_range(df_test,  ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d12d0cd-edb3-4880-997b-6510105e4068",
   "metadata": {},
   "source": [
    "Имеются явно аномальные даты из будущего в тренировочной выборке, от которых мы просто избавимся, т.к. их немного. Со старыми стартапами сложнее, т.к. сложно выбрать правильную точку отсчета начала существования старапов. Возьмем в качестве приблизительного начала отсчета 1970 год. Все записи, содержащие даты до этого года не включительно, в тренировочной выборке будут удалены. В тестовой выборке все даты, не соответствующие нижней границе, будут приведены к нижней границе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb241f-b8a1-4b47-8c39-8fe999005875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_date(df, cols):\n",
    "    for col in cols:\n",
    "        greater = df[df[col] >= pd.Timestamp('2018-01-01')].index\n",
    "        lower   = df[df[col] <  pd.Timestamp('1970-01-01')].index\n",
    "        print(f'Startups before 1970 in {col} column: {lower.shape[0]}')\n",
    "        print(f'Startups after  2017 in {col} column: {greater.shape[0]}')\n",
    "        df = df.drop(index = greater)\n",
    "        df = df.drop(index = lower)\n",
    "    return df\n",
    "\n",
    "df_train = drop_rows_date(df_train, ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d846e-9b25-4ffb-a8f7-ef488e28d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt_col in ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at']:\n",
    "    df_test[dt_col] = df_test[dt_col].clip(lower='1970-01-01')\n",
    "    print(dt_col, df_test[dt_col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cccef-598e-4b91-9bd7-404fa7152658",
   "metadata": {},
   "source": [
    "Проверим на наличие в выборке стартапов, получивших свое первое финансирование еще до своего основания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1b883-845f-4816-ac5e-e342ed8d53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['founded_at'].dt.year > df_train['first_funding_at'].dt.year].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c4eda-0ed9-4c68-b01d-25baa2a5f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['founded_at'].dt.year > df_test['first_funding_at'].dt.year].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13404f8f-ec72-4331-aeae-524e543eabc3",
   "metadata": {},
   "source": [
    "В датасетах имеются записи о стартапах, у которых первые раунды финансирования прошли до основания стартапа. Не уверен, возможно ли такое. Теоретически, можно предположить, что речь идет о получении финансирования до официального оформления бизнеса. В такой формулировке подобные преценденты вполне логичны, однако существует ли такая практика на самом деле - в этом есть некоторые сомнения. Однако на данный момент оставим подобные записи в выборке, в дальнейшем выделив новый признак, который выделит подобные записи среди общей массы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2cc65-11c4-45c2-a827-d8bc21e4a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = (df_train['closed_at'].notna()) & (df_train['status'] == 'operating')\n",
    "mask_2 = (df_train['closed_at'].isna())  & (df_train['status'] == 'closed')\n",
    "print(mask_1.sum(), mask_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447bb9e-72d5-40dc-860d-4a72b2d8077f",
   "metadata": {},
   "source": [
    "В выборке нет несоответствий даты закрытия стартапа и статуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a336c4f-4f51-48a8-a1c8-5f4987582319",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mask_1, mask_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d89bd-7ab1-4ad1-9670-2441964833ed",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c452d-291e-4f9f-a9b6-f71ae98fff8a",
   "metadata": {},
   "source": [
    "Т.к. в тренировочной выборке всего 21 запись с пропущенной датой первого раунда финансирования, присвоим таким записям в данное поле дату основания стартапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412be100-b520-4625-92e0-5feb4d2abb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_train['first_funding_at'].isna()\n",
    "df_train.loc[mask, 'first_funding_at'] = df_train[mask]['founded_at']\n",
    "df_train['first_funding_at'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc28c2e-3309-4dc7-aea3-7b6dd30c76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_train['last_funding_at'] - df_train['first_funding_at'] < pd.Timedelta(0)\n",
    "df_train[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c115384-98c9-495e-a1a9-528d28e1c427",
   "metadata": {},
   "source": [
    "Удалим строку, в которой дата последнего раунда финансирования раньше первого раунда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746469e8-2a7c-4c96-9e59-dd443888289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[~mask]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c995a-53ac-48ad-89c4-1b2c64b2df3f",
   "metadata": {},
   "source": [
    "### funding_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09ea11-afa8-4e15-b03b-c4d253f1235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_cat_distr(df, col, title='', color=palette[0]):\n",
    "#     SLICE = 15\n",
    "#     df_category = df[col].value_counts()\n",
    "#     display(df_category.to_frame()[:SLICE].T)\n",
    "    \n",
    "#     sns.set_style(\"whitegrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "    \n",
    "#     df_category[:SLICE].plot(kind='bar', stacked=True, figsize=(10, 6), width=0.8, color=color)\n",
    "    \n",
    "#     plt.xlabel('Категория', fontsize=12)\n",
    "#     plt.ylabel('Число стартапов', fontsize=12)\n",
    "#     plt.title(title, fontsize=14)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53821a-77a4-408d-9b1d-529036654a79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_col_distr_cat(df, col, slice=None, sort_index=False, sort_value=True,\n",
    "                       color=palette[0], title='', x_axis_t='', y_axis_t='', show=True, stacking_col=''):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if stacking_col != '':\n",
    "        pivot_table = df.pivot_table(index=col, columns=stacking_col, aggfunc='size', fill_value=0)\n",
    "        pivot_table.columns = ['closed', 'opened']\n",
    "        if sort_value:\n",
    "            pivot_table = pivot_table.sort_values(by=['opened', 'closed'], ascending=False)\n",
    "        if slice != None:\n",
    "            pivot_table = pivot_table[:slice]\n",
    "        display(pivot_table.T)\n",
    "\n",
    "        order = []\n",
    "        for i, cat in enumerate(df[stacking_col].unique()):\n",
    "            local_distr = df[df[stacking_col] == cat][col].value_counts()\n",
    "            if sort_index:\n",
    "                local_distr = local_distr.sort_index()\n",
    "            if len(order) == 0:\n",
    "                if slice != None:\n",
    "                    local_distr = local_distr[:slice]\n",
    "                order = local_distr.index\n",
    "            else:\n",
    "                local_distr = local_distr[pd.Index(set.intersection(set(order), set(local_distr.index)))]\n",
    "                \n",
    "            local_trace = go.Bar(x=local_distr.index, y=local_distr.values, name=cat, marker_color=palette[i], showlegend=True, opacity=0.8)\n",
    "            fig.add_trace(local_trace)\n",
    "\n",
    "        fig.update_layout(\n",
    "            barmode='stack',\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            title=title,\n",
    "            xaxis_title=x_axis_t,\n",
    "            yaxis_title=y_axis_t,\n",
    "            xaxis=dict(\n",
    "                dtick=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if show:\n",
    "            fig.show()\n",
    "            \n",
    "        return fig\n",
    "    else:\n",
    "        distr = df[col].value_counts()\n",
    "        if sort_index:\n",
    "            distr = distr.sort_index()\n",
    "            \n",
    "        if slice != None:\n",
    "            distr = distr[:slice]\n",
    "            \n",
    "        display(distr.to_frame().T.style.set_caption(' '.join(title.split(' ')[-2:])))\n",
    "        \n",
    "        trace = go.Bar(x=distr.index, y=distr.values, name='', marker_color=color, showlegend=False, opacity=0.8)\n",
    "        fig.add_trace(trace)\n",
    "    \n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            width=1000,\n",
    "            title=title,\n",
    "            xaxis_title=x_axis_t,\n",
    "            yaxis_title=y_axis_t,\n",
    "            xaxis=dict(\n",
    "                dtick=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if show:\n",
    "            fig.show()\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0febc19-6645-4a25-af40-a464761a490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fig = show_col_distr_cat(df_train, 'funding_rounds', sort_index=True, title='Funding rounds distribution for train set', stacking_col='status')\n",
    "test_tr   = show_col_distr_cat(df_test,  'funding_rounds', sort_index=True, title='Funding rounds distribution for test set', color=palette[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2ca74-b75c-447f-8dce-05f02f068d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['funding_rounds'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb17fee-c624-49d8-86ee-c19594aeeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_train['first_funding_at'] == df_train['last_funding_at']) & (df_train['funding_rounds'] > 1)\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c3f42-fc35-40a9-a79d-aae00b5dc31d",
   "metadata": {},
   "source": [
    "В выборке имеются записи, в которых число раундов финансирования больше 1, но при этом даты первого и последнего раунда совпадают. Заменим в таких строках число раундов на единицу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5afda7-ce1d-4eff-953b-58e52238e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[mask, 'funding_rounds'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eec7b6-4692-469a-a97b-d6de75d7ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_test['first_funding_at'] == df_test['last_funding_at']) & (df_test['funding_rounds'] > 1)\n",
    "print(mask.sum())\n",
    "df_test.loc[mask, 'funding_rounds'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3b061-ae51-4566-900e-fdf33d9ad446",
   "metadata": {},
   "source": [
    "### funding_total_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c06674-50e6-447a-912c-8379958be5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_boxplot(df, col, color=palette[0], title='', show=True):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    trace = go.Box(y=df[col], name='', marker_color=color, showlegend=False)\n",
    "    fig.add_trace(trace)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=400,\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486dd4f-d005-4d85-99f5-47d4892a0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_total_train_tr = plot_boxplot(df_train, 'funding_total_usd', show=False)\n",
    "fund_total_test_tr  = plot_boxplot(df_test,  'funding_total_usd', color=palette[1], show=False)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['train', 'test'])\n",
    "    \n",
    "fig.add_trace(fund_total_train_tr, row=1, col=1)\n",
    "fig.add_trace(fund_total_test_tr, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    title='funding_total_usd boxplots'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "display(df_train['funding_total_usd'].describe().to_frame().T.style.set_caption('train set'), \n",
    "        df_test['funding_total_usd'].describe().to_frame().T.style.set_caption('test set'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c93260-cb7a-43a2-96f1-02a134780ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_funding_total(df):\n",
    "    rows_to_delete = df[df['funding_total_usd'] > 5e9].index\n",
    "    print(f'Startups with total fundings greater than 5b $: {rows_to_delete.shape[0]}')\n",
    "    df = df.drop(index = rows_to_delete)\n",
    "    return df\n",
    "\n",
    "df_train = drop_rows_funding_total(df_train)\n",
    "# df_test  = drop_rows_funding_total(df_test)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f399432d-1857-41ed-870c-5d6a76e43365",
   "metadata": {},
   "source": [
    "Графики выше показывают, что имеются выбивающиеся суммы инвестиций. Удалим все стартапы, суммарные инвестиции в которые превышают 5 миллиардов долларов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41712e-575d-4a0f-8946-d26a2a6d26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of startupds with total fundings lower than 10k$: ', df_train.query('funding_total_usd < 10000').shape[0])\n",
    "# df_train = df_train.drop(index=df_train.query('funding_total_usd < 10000').index)\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd908ee1-af96-4eee-b2db-1a69a4e166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_col_distr_num(df, col, color=palette[0], title='', show=True):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    trace = go.Histogram(x=df[col], name='', marker_color=color, showlegend=False)\n",
    "    fig.add_trace(trace)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        title=title,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        fig.show()\n",
    "\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674669d3-4210-4da1-8d8a-86ed7cbaaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_total_train_tr = show_col_distr_num(df_train, 'funding_total_usd', show=False)\n",
    "fund_total_test_tr  = show_col_distr_num(df_test,  'funding_total_usd', color=palette[1], show=False)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['train', 'test'])\n",
    "    \n",
    "fig.add_trace(fund_total_train_tr, row=1, col=1)\n",
    "fig.add_trace(fund_total_test_tr, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    title='funding_total_usd distributions'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b077b56-b4e9-49ce-b0f2-c9e16a87342d",
   "metadata": {},
   "source": [
    "### country_code / state_code / region / city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bf6f5-3f00-457f-9033-93c909c1031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_code'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898d121-cae8-45ae-aae4-8287f7559e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9c21b-dada-4a57-9302-b9aa0aa1c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['city'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34453c-d3f7-406f-ad7c-c525ca7e4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['state_code'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260ce0e-bd5d-443c-9920-1f5d7a3ec2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Страны, у которых есть своя собственная кодировка штатов/регионов\n",
    "df_train[df_train['state_code'].notna()]['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca087dc-2821-425f-8b20-880a747d204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['state_code'].isna()].groupby('country_code')['state_code'].apply(lambda x: x.isna().sum()).sort_values(ascending=False).to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4461898-e319-48a1-8435-b753fb888629",
   "metadata": {},
   "source": [
    "### category_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ca75e-c76c-4403-90e9-fe6591760d6e",
   "metadata": {},
   "source": [
    "В связи с наличием комбинированных категорий необходимо упростить их до одной категории, чтобы в дальнейшем было возможно присвоить стартапу соответсвтующую уникальную группу. Для этого определим список рейтинг популярности одиночных категорий, после чего вместо комбинированной категории оставим лишь одну категорию, которая в рейтинге стоит выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60529d97-7585-4dbb-9963-74eb0a9340f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list_splitted = [item.split('|') for item in df_train.category_list.fillna('').str.lower()]\n",
    "category_counts = Counter(category for sublist in category_list_splitted for category in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fc71b-3103-4e4f-a42f-88b7f7ccc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_category(df, category_counts):\n",
    "    category_list_splitted = [item.split('|') for item in df['category_list'].fillna('').str.lower()]\n",
    "    main_categories_list   = [[category for category in sorted(sublist, key=lambda x: -category_counts.get(x, 0))][0] for sublist in category_list_splitted]\n",
    "    return main_categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4bbf5-3752-4681-8a14-e25730a94a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['main_category'] = get_main_category(df_train, category_counts)\n",
    "df_test['main_category']  = get_main_category(df_test, category_counts)\n",
    "print(df_train.shape, df_test.shape)\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d99257-cbc0-43d5-968e-fc80372353ff",
   "metadata": {},
   "source": [
    "### status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4a4e5-43cf-4309-8a50-c39c8613d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bfd58-b59c-4f03-9886-ad88919b9f38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616e6f0-45b0-4f36-b498-c64d19572870",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc9e33-2e45-4e6d-8029-5b232d64f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "sns.heatmap(df_train.isnull(), cbar=False, ax=axes[0])\n",
    "axes[0].set_title('Missing values in df_train')\n",
    "\n",
    "sns.heatmap(df_test.isnull(), cbar=False, ax=axes[1])\n",
    "axes[1].set_title('Missing values in df_test')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c36ef6-a43c-4aa1-9e02-7658464523cb",
   "metadata": {},
   "source": [
    "Из графика выше можно выделить, что в большинстве случаев пропуски в данных, связанных с географическим происхождением старапов, имеются сразу во всех соответствующих столбцах. Это означает, что восстановить какую-либо информацию по косвенным признакам скорее всего будет крайне затруднительно в связи с отсутствием сразу всех географических данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e1d39-9173-4997-9c29-1efcd736d6f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_size(df, column, labels, explode, palette):\n",
    "    values = df[column].value_counts()\n",
    "    display(values.to_frame())\n",
    "    \n",
    "    lb = ''\n",
    "    if labels == '':\n",
    "        lb = values.index\n",
    "    else:\n",
    "        lb = labels\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 10), tight_layout=True)\n",
    "\n",
    "    ax[0].bar(lb, values, color=palette)\n",
    "    ax[0].grid(True, color='grey', axis='y', linestyle='-.', linewidth=0.5, alpha=0.6)\n",
    "    ax[0].set_xlabel('Class', fontsize=16)\n",
    "    ax[0].set_ylabel('Number of clients', fontsize=14)\n",
    "    ax[0].set_title(f'Number of clients over \"{column}\" attribute', fontsize=14)\n",
    "    ax[0].bar_label(ax[0].containers[0], \\\n",
    "                 label_type='center', fmt='%.2f', fontsize=14, color='white')\n",
    "    ax[0].tick_params(axis='x', labelsize=12)\n",
    "    ax[0].tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    pie, _, _ = ax[1].pie(\n",
    "                            values, \n",
    "                            labels=values.index, \n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=150, \n",
    "                            textprops={'fontsize': 12},\n",
    "                            colors=sns.color_palette('Set2'),\n",
    "                            explode=explode,\n",
    "                            # wedgeprops={'width': 0.4}  # Adjust the width to change the size of the hole\n",
    "                        )\n",
    "    plt.setp(pie, edgecolor='black', linewidth=0.3)\n",
    "    ax[1].set_title('Distribution of Startup Status', fontsize=15, pad=10)\n",
    "    ax[1].axis('equal')\n",
    "    ax[1].set_title(f'Percentage of clients over \"{column}\" attribute ', fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d4a1-f07d-4d2a-aa96-b1d2fc83090c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_tab(df, column, slice=10, filter_value=100, sort_by_ratio=False, horizontal=False):\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    \n",
    "    tab = pd.crosstab(df[column], df['status'])\n",
    "    tab['ratio'] = tab['closed'] / (tab['closed'] + tab['operating']) * 100\n",
    "    if sort_by_ratio:\n",
    "        tab = tab[tab['operating'] > filter_value]\n",
    "        tab = tab.sort_values(by=['ratio'], ascending=False)\n",
    "        \n",
    "    display(tab[:slice])\n",
    "    tab = tab.drop(columns=['ratio'])\n",
    "\n",
    "    if horizontal:\n",
    "        tab.div(tab.sum(axis=1), axis=0)[slice::-1].plot(kind=\"barh\", stacked=True, color=[palette[1], palette[2]], ax=ax)\n",
    "        ax.set_xlabel('Proportion', fontsize=12)\n",
    "        ax.set_ylabel(column, fontsize=12)\n",
    "        ax.grid(True, color='grey', axis='x', linestyle='-.', linewidth=0.5, alpha=0.6)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xticks([0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0])        \n",
    "        ax.legend(title='status', loc='upper left', labels=['closed', 'operating'], bbox_to_anchor=(1, 1))\n",
    "        ax.axvline(x=0.5, color='black', linestyle='--', alpha=0.7)\n",
    "    else:\n",
    "        tab.div(tab.sum(axis=1), axis=0)[:slice].plot(kind=\"bar\", stacked=True, color=[palette[1], palette[2]], ax=ax)\n",
    "        ax.set_xlabel(column)\n",
    "        ax.set_ylabel('Proportion')\n",
    "        ax.grid(True, color='grey', axis='y', linestyle='-.', linewidth=0.5, alpha=0.6)\n",
    "        ax.legend(title='status', loc='upper left', labels=['closed', 'operating'], bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.xticks(rotation=0)\n",
    "    ax.bar_label(ax.containers[0], label_type='center', fmt='%.2f')\n",
    "    ax.bar_label(ax.containers[1], label_type='center', fmt='%.2f')\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    ax.set_title(f'Stacked Bar Chart of {column} vs. status')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c873c-9cc7-48ce-9f3f-c3083931143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size(df_train, 'status', labels='', explode=(0, 0.05), palette=sns.color_palette('Set2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12c840-2e04-42d1-acf6-9f72e77bb1c4",
   "metadata": {},
   "source": [
    "Имеется ярко выраженный дисбаланс классов. Закрывшихся стартапов в выборке в 10 раз меньше, чем стартапов, продолжающих функционировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0df40-deba-4474-ba39-77dce41b83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_col_distr_cat(df_train, 'country_code', slice=15, stacking_col='status',\n",
    "                       title='Число стартапов по странам', x_axis_t='страны', y_axis_t='кол-во',\n",
    "                       color=palette[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e57e2-8804-4daf-93b0-99ceefaf4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Доля стартапов из США: {df_train[df_train['country_code'] == 'USA'].shape[0] / df_train.shape[0] * 100:.2f}%')\n",
    "print(f'Доля стартапов из Великобритании: {df_train[df_train['country_code'] == 'GBR'].shape[0] / df_train.shape[0] * 100:.2f}%')\n",
    "print(f'Доля стартапов из Великобритании: {df_train[df_train['country_code'] == 'CAN'].shape[0] / df_train.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874438b-756e-44fa-ba1f-79ea9f9c66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tab(df_train, 'country_code', slice=15, filter_value=50, sort_by_ratio=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8407c59-f697-4e5d-9b1f-4749a9b1dd70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_pivot_table(df, index, closed=False, filter_value=100, title='', x_axis_t='', y_axis_t='', color=palette[0], orientation='v'):\n",
    "    pivot_table = df.pivot_table(index=index, columns='status', aggfunc='size', fill_value=0)\n",
    "    pivot_table.columns = ['closed', 'opened']\n",
    "    pivot_table = pivot_table[pivot_table['opened'] > filter_value] # уберем совсем редкие категории стартапов\n",
    "    ratio = ''\n",
    "    if closed:\n",
    "        ratio = pd.DataFrame(\n",
    "                              data=[c / (o + c) * 100 for o, c in zip(pivot_table['opened'], pivot_table['closed'])], \n",
    "                              index=pivot_table.index,\n",
    "                              columns=['ratio']\n",
    "                            ).sort_values(by=['ratio'], ascending=False)\n",
    "    else:\n",
    "        ratio = pd.DataFrame(\n",
    "                              data=[o / (o + c) * 100 for o, c in zip(pivot_table['opened'], pivot_table['closed'])], \n",
    "                              index=pivot_table.index,\n",
    "                              columns=['ratio']\n",
    "                            ).sort_values(by=['ratio'], ascending=False)\n",
    "    display(ratio.head(10).T)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    if orientation == 'v':\n",
    "        trace = go.Bar(x=ratio.index, y=ratio.ratio, name='', marker_color=color, showlegend=False, opacity=0.8)\n",
    "    elif orientation == 'h':\n",
    "        trace = go.Bar(y=ratio.index[::-1], x=ratio.ratio[::-1], name='', marker_color=color, orientation=orientation, showlegend=False, opacity=0.8)\n",
    "    fig.add_trace(trace)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=1000,\n",
    "        title=title,\n",
    "        xaxis_title = x_axis_t if orientation=='v' else y_axis_t,\n",
    "        yaxis_title = y_axis_t if orientation=='v' else x_axis_t,\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ce106-f127-4fa6-ae93-fd885172bd73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_pivot_table(df_train, \n",
    "                 'country_code', \n",
    "                 closed=True, \n",
    "                 filter_value=50, \n",
    "                 title='Доля провальных стартапов по странам', \n",
    "                 x_axis_t='страны', \n",
    "                 y_axis_t='доля',\n",
    "                 orientation='h',\n",
    "                 color=palette[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e94fc-e8ad-4e86-a8f5-11f2d5400d13",
   "metadata": {},
   "source": [
    "Страной, в которой было зафиксировано самое большое число стартапов, являются США. На стартапы из США приходится более половины всех записей в выборке - почти 57%. Великобритания находится на втором месте по числу стартапов, но ее доля в 10 раз меньше, чем у США - 5.57%. Далее по нисходящей. При этом, что примечательно, доля провальных стартапов в США меньше, чем во многих других странах. США находится приблизительно посередине по показателю доли закрывшихся стартапов.\n",
    "\n",
    "Странами с самым большим числом закрывшихся стартапов являются Россия(доля провалов равна 35.5%), Бразилия(11.8%), Новая Зеландия(11.7%), Аргентина и Швеция(11.68% и 11.26% соответственно). В данном случае были учтены страны, в которых было открыто более 50 стартапов.\n",
    "\n",
    "Меньше всего стартапов было свернуто в Португалии, Чили, ОАЭ, Индии и Турции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364badd3-0035-4032-b056-77847ad5e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_col_distr_cat(df_train, 'city', slice=30, stacking_col='status',\n",
    "                       title='Число стартапов по городам', x_axis_t='города', y_axis_t='кол-во',\n",
    "                       color=palette[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2acaae-883b-4fc1-b80b-2215260f5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cat = df_train[df_train['main_category'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0d15f-79bd-4000-913c-3909bc5969a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = show_col_distr_cat(df_train_cat, 'main_category', slice=15, stacking_col='status',\n",
    "                       title='Число стартапов по категориям', x_axis_t='категории', y_axis_t='кол-во',\n",
    "                       color=palette[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc2588-6fa2-4953-b31a-96c83f77ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tab(df_train_cat, 'main_category', slice=10, sort_by_ratio=True, horizontal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e97cc5-9f2a-4cee-95c6-0ea3accf6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pivot_table(df_train_cat, \n",
    "                 'main_category', \n",
    "                 filter_value=100, \n",
    "                 closed=False, \n",
    "                 title='Доля функционирующих стартапов по категориям', \n",
    "                 x_axis_t='категория', \n",
    "                 y_axis_t='доля, %', \n",
    "                 color=palette[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b75b6-353d-4234-bd1c-24ff29adbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pivot_table(df_train_cat, \n",
    "                 'main_category', \n",
    "                 filter_value=100, \n",
    "                 closed=True, \n",
    "                 title='Доля провальных стартапов по категориям', \n",
    "                 x_axis_t='категория', \n",
    "                 y_axis_t='доля, %', \n",
    "                 color=palette[1])\n",
    "\n",
    "del df_train_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa88af5-a94c-48c8-a41e-6779ad21cd05",
   "metadata": {},
   "source": [
    "Графики выше демонстрируют отношение направленности стартапа к числу провальных стартапов в данной области, а также в целом распределение записей по категориям.\n",
    "\n",
    "Если говорить о распределении по категориям, то здесь стоит отметить категорию \"software\" как самую распространенную в выборке. Число стартапов, соответствующих данной категории, почти в 2 раза больше размеров следующей по популярности категории. В пятерку самых распространенных категорий входят: software, biotechnology, mobile, e-commerce, curated web. Следом идут enterprise software, healthcare и games. В целом среди самых популярных стартапов превалируют категории, связанные с цифровой или технической сферой.\n",
    "\n",
    "Для некоторых из самых популярных категорий стартапов наблюдается также и более высокая доля провальных бизнесов. Например, curated web является 5 по распространенности категорией, будучи при этом 2 среди по доле провальных случаев. Games - 8 по популярности и 11 по проценту провалов категория. Software - 1 по популярности и 22 по проценту провалов. И т.д. В целом это ожидаемо: чем больше молодых стартапов пытается развиться, тем в общем больше шансов, что кого-нибудь постигнет неудача."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f7ba2-9a56-4198-94e2-4d4a794a4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr = show_col_distr_cat(df_train, 'funding_rounds', color=palette[0], title='Funding rounds distribution for train set', show=False)\n",
    "test_tr  = show_col_distr_cat(df_test,  'funding_rounds', color=palette[1], title='Funding rounds distribution for test set', show=False)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['train', 'test'])\n",
    "    \n",
    "fig.add_trace(train_tr, row=1, col=1)\n",
    "fig.add_trace(test_tr, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    title='funding_total_usd distributions',\n",
    "    xaxis=dict(dtick=1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b55e0-5554-4438-bd49-445218e7aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e3164-6bff-4f3d-9cb3-c8646321ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_status = pd.DataFrame(df_train[['status', 'funding_rounds']])\n",
    "pivot_table = df_status.pivot_table(index='funding_rounds', columns='status', aggfunc='size', fill_value=0)\n",
    "pivot_table.columns = ['closed', 'opened']\n",
    "close_ratio = pd.Series(\n",
    "                        data=[c / (o + c) * 100 for o, c in zip(pivot_table['opened'], pivot_table['closed'])], \n",
    "                        index=pivot_table.index\n",
    "                       )\n",
    "\n",
    "display(pivot_table.T)\n",
    "display(close_ratio.to_frame().T.style.background_gradient(cmap='YlOrRd', axis=1))\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=close_ratio.index, y=close_ratio.values)\n",
    "plt.xticks(range(0, len(close_ratio) + 1, 1))\n",
    "plt.ylabel('%', fontsize=12)\n",
    "plt.xlabel('Funding Rounds', fontsize=12)\n",
    "plt.title('Отношение числа закрытых стартапов к общему числу стартапов по числу раундов финансирования', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9c26d-e77b-453c-a0b5-6932906d4152",
   "metadata": {},
   "source": [
    "- В выборке представлены только стартапы, получившие финансирование хотя бы один раз.\n",
    "- Имеется некоторая вполне ожидаемая тенденция к снижению числа провальных стартапов с каждым следующим раундом финансирования. Такое поведение справедливо вплоть до 8 раунда инвестиций. График выше показывает некоторое несоответствие общему тренду отношения числа закрытых стартапов к общему их числу в промежутке между 7 и 12 раундом. Но стоит учитывать, что это несущественная проблема, учитывая маштаб общего числа стартапов, прошедших данные итерации финансирования. С 12 раунда и далее число закрывшихся стартапов равно 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58d760-b1e4-4a5f-bc14-701c288a24a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['funding_total_usd'].describe().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a43edd-0a64-4cda-a3f2-4dcb6b327e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_fund_train = pd.DataFrame(data=df_train['funding_total_usd'].apply(np.log))\n",
    "                                                                         \n",
    "df_log_fund_test  = pd.DataFrame(data=df_test['funding_total_usd'].apply(np.log))\n",
    "\n",
    "df_log_fund_train.columns = ['log_funding_total']\n",
    "df_log_fund_test.columns = ['log_funding_total']\n",
    "\n",
    "display(df_log_fund_train.describe().T, df_log_fund_test.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d077b-de9c-4bfe-b971-88ed02115e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_class(df, col, title=''):\n",
    "    opened = df[df['status'] == 'operating'][col]\n",
    "    closed = df[df['status'] == 'closed'][col]\n",
    "\n",
    "    sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.scatter(x=opened, y=[0] * opened.shape[0])\n",
    "    plt.scatter(x=closed, y=[1] * closed.shape[0])\n",
    "\n",
    "    plt.yticks([0, 1], ['Operating', 'Closed'])\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel('status', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d325310-4559-4f0a-91d1-42d7fb7fa18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_fund_train['status'] = df_train['status']\n",
    "\n",
    "plot_scatter_class(df_log_fund_train, 'log_funding_total', title='Разброс log_funding_total по статусу стартапа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b8ad-e339-43ab-8721-2d2d23d8fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distr_sns(df, col, color=palette[0], title=''):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    sns.histplot(df[col], kde=True, color=color)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512ce0b-f462-4f88-8762-48d9076b5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund_total_train_tr = show_col_distr_num(df_log_fund_train, 'log_funding_total', show=False)\n",
    "# fund_total_test_tr  = show_col_distr_num(df_log_fund_test,  'log_funding_total', color=palette[1], show=False)\n",
    "\n",
    "show_distr_sns(df_log_fund_train, 'log_funding_total', title='Распределение funding_total_usd после log-преобразования (трейн)')\n",
    "show_distr_sns(df_log_fund_test,  'log_funding_total', color=palette[1], title='Распределение funding_total_usd после log-преобразования (тест)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c2ff1-f610-4640-b4e7-efe0abc615c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fund_total_train_tr = plot_boxplot(df_log_fund_train, 'log_funding_total', show=False)\n",
    "fund_total_test_tr  = plot_boxplot(df_log_fund_test,  'log_funding_total', color=palette[1], show=False)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=['train', 'test'])\n",
    "    \n",
    "fig.add_trace(fund_total_train_tr, row=1, col=1)\n",
    "fig.add_trace(fund_total_test_tr, row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    title='log funding_total_usd boxplots'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3d748-a7b9-452e-99d6-9b533fc90327",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_outliers(data):\n",
    "    series = pd.Series(data)\n",
    "    \n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    LF = Q1 - 1.5 * IQR\n",
    "    UF = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = series[(series < LF) | (series > UF)]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611c72e-8052-4f0a-85cf-6817e1de8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Выбросов до преобразования: ', len(find_outliers(df_train['funding_total_usd'])))\n",
    "print('Выбросов после преобразования: ', len(find_outliers(df_log_fund_train['log_funding_total'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35735b6c-b5fe-4d3b-9574-64a30e81632c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def perform_normality_tests(data):\n",
    "    statistic, pvalue = st.jarque_bera(data)\n",
    "    if pvalue > 0.05:\n",
    "        result = 'Normal'\n",
    "    else:\n",
    "        result = 'NOT Normal'\n",
    "    print(f'Jarque-Bera: {result:>20s}')\n",
    "    print(statistic)\n",
    "    print(f'p-value: {pvalue}')\n",
    "\n",
    "    ksstat, pvalue = sm.stats.diagnostic.lilliefors(data)\n",
    "    if pvalue > 0.05:\n",
    "        result = 'Normal'\n",
    "    else:\n",
    "        result = 'NOT Normal'\n",
    "    print(f'Lilliefors: {result:>30}')\n",
    "    print(ksstat)\n",
    "    print(f'p-value: {pvalue}')\n",
    "\n",
    "    statistic, pvalue = st.normaltest(data)\n",
    "    if pvalue > 0.05:\n",
    "        result = 'Normal'\n",
    "    else:\n",
    "        result = 'NOT Normal'\n",
    "    print(f'Normaltest: {result:>20s}')\n",
    "    print(statistic)\n",
    "    print(f'p-value: {pvalue}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfffd1-8da9-4f7e-aa7b-a1e920e60482",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_normality_tests(df_log_fund_train['log_funding_total'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2396b0-f9dd-4967-96d6-cd753cf38cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_normality_tests(df_log_fund_test['log_funding_total'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71257d-b964-4f73-86a8-ac3076e58b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_log_fund_train\n",
    "del df_log_fund_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740de169-b850-4f72-b033-4aa6c14cc8d4",
   "metadata": {},
   "source": [
    "Т.к. ранее в процессе предобработки был замечен сильный скос графика распределения признака вправо, использовано log-преобразование, чтобы получить более плотное распределение с более \"приятными\" статистическими свойствами, в котором нет значительных выбросов, как это было в данных до преобразования. Хотя полученное распределение издалека напоминает нормальное распределение, тесты на нормальность показывают, что это не так. Но даже так полученное распределение выглядит намного лучше изначального. Кроме того, после преобразования количество выбросов, не попадающих в полтора межквартильных размаха, уменьшилось с 5874 до 158."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae3bba-2663-417d-8f76-f7627ab4d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_stats_train = df_train.groupby(df_train['founded_at'].dt.year)['funding_rounds'].count()\n",
    "foundation_stats_test  = df_test.groupby(df_test['founded_at'].dt.year)['funding_rounds'].count()\n",
    "\n",
    "display(foundation_stats_train.to_frame().T.style.set_caption('train set'))\n",
    "display(foundation_stats_test.to_frame().T.style.set_caption('test set'))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(x=foundation_stats_train.index, y=foundation_stats_train.values, ax=ax[0])\n",
    "sns.lineplot(x=foundation_stats_test.index,  y=foundation_stats_test.values,  ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Число открывшихся стартапов по годам (train)')\n",
    "ax[1].set_title('Число открывшихся стартапов по годам (test)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4903ff7-475e-4098-8391-afe59e343f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_year = df_train.groupby([df_train['founded_at'].dt.year, 'status']).size().unstack(level='status').fillna(0)\n",
    "df_train_year = df_train_year[df_train_year.columns[::-1]]\n",
    "display(df_train_year.T)\n",
    "\n",
    "sns.set_style(\"whitegrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "\n",
    "df_train_year.plot(kind='bar', stacked=True, figsize=(10, 6), width=0.8, color=palette)\n",
    "\n",
    "plt.xlabel('Год')\n",
    "plt.ylabel('Число стартапов')\n",
    "plt.title('Состояние стартапов по годам')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig = go.Figure()\n",
    "# for i, col in enumerate(df_train_year.columns):\n",
    "#     local_distr = df_train_year[col]\n",
    "#     local_trace = go.Bar(x=local_distr.index, y=local_distr.values, name=col, marker_color=palette[i], showlegend=True)\n",
    "#     fig.add_trace(local_trace)\n",
    "\n",
    "# fig.update_layout(\n",
    "#     barmode='stack',\n",
    "#     height=600,\n",
    "#     width=800,\n",
    "#     title='Состояние стартапов по годам',\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab6a87-9f98-4664-9b6e-b98cb614c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = [(new_year - prev_year) / prev_year * 100 for prev_year, new_year in zip(foundation_stats_train[0::], foundation_stats_train[1::])]\n",
    "growth = pd.Series(data=growth[:-1], index=foundation_stats_train.index[1:-1])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.set_style(\"whitegrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "plt.title('Процентный рост числа стартапов в сравнении с прошлым годом', size=16)\n",
    "plt.ylabel('Рост, %',size=12)\n",
    "plt.xlabel('Год',size=12)\n",
    "plt.axhline(0, linestyle='-.', color='red')\n",
    "plt.plot(growth.index, growth.values, label='Рост',color='green',linewidth=3)\n",
    "plt.xticks(growth.index[::5])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74989e5f-120d-410b-8910-bfc479f53340",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_ratio = pd.Series(\n",
    "                        data=[c / (o + c) * 100 for o, c in zip(df_train_year['operating'], df_train_year['closed'])], \n",
    "                        index=df_train_year.index\n",
    "                       )[:-1]\n",
    "\n",
    "display(close_ratio.to_frame().T)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.set_style(\"whitegrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
    "plt.title('Доля провальных стартапов по годам основания', size=16)\n",
    "plt.ylabel('% провалов',size=12)\n",
    "plt.xlabel('Год',size=12)\n",
    "plt.plot(close_ratio.index, close_ratio.values, label='Процент провалов',color='red',linewidth=3)\n",
    "plt.axhline(close_ratio.values.mean(), label='Средний уровень провалов за всё время', linestyle='-.')\n",
    "plt.legend()\n",
    "plt.xticks(close_ratio.index[::5])\n",
    "plt.yticks(range(0, int(max(close_ratio.values)) + 1, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab11450-1ab5-4c46-b737-698e609c4f2f",
   "metadata": {},
   "source": [
    "Графики выше предназначены больше для ознакомления с датасетом, нежели для нахождения закономерностей, полезных для предсказательной модели.\n",
    "\n",
    "Как можно заметить, с каждым годом число новых стартапов росло, особенно резко рост начался приблизительно 1995-96 году, когда число стратапов начало увеличиваться экспоненциально. На графике также видно две условные ступени, когда рост тормозился. Такие проблемы возникли в 2000 и 2008 году, что, разумеется, имеет исторический контекст (dot-com bubble и мировой экономический кризис, начавшийся в 2008 году).\n",
    "\n",
    "График отношения числа провальных стартапов к общему числу стартапов по году создания стартапа имеет скачкообразное поведение вплоть до 1985-88 года. Связано это с небольшим числом стартапов, открывшихся в этот период. Более устойчивое и читаемое поведение графика начинается далее в связи с ростом числа стартапов. До 1997 года провальных стартапов в среднем было менее 10%. С 97 по 2006-2007 данное соотношение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b786a53-239d-4122-a7d1-09de498af0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_founded_before_funding = df_train[df_train['founded_at'].dt.year <= df_train['first_funding_at'].dt.year].copy(deep=True)\n",
    "df_founded_after_funding  = df_train[df_train['founded_at'].dt.year >  df_train['first_funding_at'].dt.year].copy(deep=True)\n",
    "\n",
    "df_founded_before_funding['year_of_foundation'] = df_founded_before_funding['founded_at'].dt.year\n",
    "df_founded_after_funding['year_of_foundation']  = df_founded_after_funding['founded_at'].dt.year\n",
    "df_founded_after_funding  = df_founded_after_funding[df_founded_after_funding['year_of_foundation'] != 2016]\n",
    "df_founded_before_funding = df_founded_before_funding[df_founded_before_funding['year_of_foundation'] \n",
    "                                                      >= df_founded_after_funding['year_of_foundation'].min()]\n",
    "\n",
    "pivot_table_before = df_founded_before_funding.pivot_table(index='year_of_foundation', columns='status', aggfunc='size', fill_value=0)\n",
    "pivot_table_after  = df_founded_after_funding.pivot_table(index='year_of_foundation',  columns='status', aggfunc='size', fill_value=0)\n",
    "\n",
    "pivot_table_before.columns = ['closed', 'opened']\n",
    "pivot_table_after.columns  = ['closed', 'opened']\n",
    "\n",
    "display(pivot_table_before.T.style.set_caption('founded before funding'), \n",
    "        pivot_table_after.T.style.set_caption('founded after funding'))\n",
    "\n",
    "close_ratio_before = pd.Series(\n",
    "                                data=[c / (o + c) * 100 for o, c in zip(pivot_table_before['opened'], pivot_table_before['closed'])], \n",
    "                                index=pivot_table_before.index\n",
    "                              )\n",
    "close_ratio_after  = pd.Series(\n",
    "                                data=[c / (o + c) * 100 for o, c in zip(pivot_table_after['opened'], pivot_table_after['closed'])], \n",
    "                                index=pivot_table_after.index\n",
    "                              )\n",
    "\n",
    "\n",
    "display(close_ratio_before.to_frame().T.style.set_caption('founded before funding, ratio'), \n",
    "        close_ratio_after.to_frame().T.style.set_caption('founded after funding, ratio'))\n",
    "df_combined = pd.concat([close_ratio_before, close_ratio_after], axis=1)\n",
    "df_combined.columns = ['before funding', 'after funding']\n",
    "df_combined.loc[1997, 'after funding'] = 0.0\n",
    "df_combined['year_of_foundation'] = df_combined.index\n",
    "df_combined = df_combined.reset_index(drop=True)\n",
    "df_combined = df_combined.melt(id_vars='year_of_foundation', var_name='Category', value_name='Ratio')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(x='year_of_foundation', y='Ratio', hue='Category', data=df_combined, palette='muted')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Year of Foundation', fontsize=12)\n",
    "plt.ylabel('Ratio (%)', fontsize=12)\n",
    "plt.title('Сравнение % закрывшихся стартапов среди основанных до или после первого раунда финансирования', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Founded')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a5ce9-9dbc-4fad-a50d-8b10bb8c6369",
   "metadata": {},
   "source": [
    "График выше сравнивает отношение числа закрывшихся - провальных - стартапов к общему числу стартапов, созданных в каждом году. При этом сравнивается отношение двух подвыборок. Первая является подвыборкой стартапов, получивших свое первое финансирование еще до своего основания (оранжевые столбцы). Вторая подвыборка наоборот состоит из тех стартапов, у которых первый раунд финансирования прошел уже после основания фирмы (синие столбцы). Здесь стоит отметить несколько моментов. Во-первых, выборка содержит относительно небольшое число записей, относящихся к первой подвыборке - всего около 1200 строк при общем размере тестового датасета в более чем 50000 строк. Во-вторых, стартапы первой подвыборки равномерно распределены по годам основания лишь с 2005 года. До этого момента примеры таких бизнесов встречаются лишь в 1999 году.\n",
    "\n",
    "Если сравнивать проценты провальных стартапов лишь в те года, для которых имеется информация об обеих подвыборках, то можно заметить некоторое непостоянство. Ровно в половине случаев стартапы с \"превентивным\" финансированием проваливались заметно (иногда более чем в 2 раза) чаще второй категории стартапов. Однако в другой половине случаев стартапы, получавшие финансирование уже после своего создания, проваливались чаще первой категории. Хотя в данном случае разница в процентном отношении не такая впечатляющая, как в первой случае: разница варьируется от менее чем 0.1% до приблизительно 5%, лишь в 2015 году разница составила порядка 12%, в то время как в случае большего числа провалов среди стартапов первой группы разница находится в интервале от 1.76% до 18%.\n",
    "\n",
    "Говорить о существовании какой-либо закономерности в данном случае тяжело, т.к. не удалось установить однозначной тенденции к более частому провалу среди рассмотренных категорий стартапов. Единственное, что можно с натяжкой определить как существующую разницу - более высокую долю провалов стартапов, профинансированных до своего основания, в случаях, когда выдавался более провальный год именно для них. Однако, что более вероянтно, такая разница связана с размерами подвыборок. Всё-таки выборка таких стартапов значительно меньше второй категории, что заставляет сомневаться в статистической устойчивости полученных наблюдений.\n",
    "\n",
    "Если учитывать всё скананное ранее, проводить подобную дихотомию скорее является излишниш и вряд ли приведет к дальнейшему улучшению модели. Однако можно рассмотреть возможность проведения экспериментов, в рамках которых будут сравниваться модели, обученные на выборках с новым признаком, классифицирующим стартапы описанным выше способом, и без такого признака. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd34f6e-a710-4568-8a8d-5ff7860f514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_last_funding_gap = df_train['last_funding_at'] - df_train['first_funding_at']\n",
    "first_last_funding_gap = first_last_funding_gap.dt.days\n",
    "first_last_funding_gap = first_last_funding_gap.dropna().astype(int)\n",
    "first_last_funding_gap = pd.DataFrame(data=first_last_funding_gap.values, index=first_last_funding_gap.index, columns=['range']).sort_values(by='range')\n",
    "first_last_funding_gap = first_last_funding_gap[first_last_funding_gap['range'] > 0]\n",
    "first_last_funding_gap['status'] = df_train['status']\n",
    "first_last_funding_gap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c718163-2db7-4c42-8dad-5068f3eee5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_class(first_last_funding_gap, 'range', title='Разброс времени между первым и последним раундом финансирования по статусу стартапа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f568898-6cc1-43aa-9194-044653c271b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train[df_train['last_funding_at'] - df_train['first_funding_at'] > pd.Timedelta(3000, 'd')][['funding_rounds', 'status']]\n",
    "tmp.groupby('status').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a9df9-dd62-4ec2-bed1-8c3f2e91f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['funding_rounds'].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c773aa-527a-4407-8e22-e42a7d8fc589",
   "metadata": {},
   "source": [
    "Анализ времени между первым и последним раундом финансирования показывает, что возможно установить такой порог для временной дельты, после которого останутся только функционирующие стартапы. Однако доля выделенных записей совсем незначительна, так что особой пользы от подобного заключения получить вряд ли получится."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650b03c-d3bc-4ce2-b210-1ed37e408245",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fdf1b-6958-4eb6-b55d-b99e7e0c470d",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9fce9-9bba-423d-b6e2-a8a9aa2c3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728020b-db5b-4f5d-ac4d-9f2e65280cb2",
   "metadata": {},
   "source": [
    "### category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583cbd3-2039-4e5f-a2db-ea49ae4092ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unique_cats = sorted(df_train.category_list.str.lower().str.replace(' ', '').str.split('|').explode().str.strip().dropna().unique())\n",
    "unique_cats = sorted(df_train.category_list.str.lower().str.split('|').explode().str.strip().dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41254304-1e1f-4661-8549-a4ef49f7a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b213f-a7ef-4edb-9137-2ac85dc0bb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(unique_cats[:10], unique_cats[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93f0c1-3ccd-4fc0-94fa-dc001aad4973",
   "metadata": {},
   "source": [
    "Создадим, пока в отдельной переменной, список, содержащий разбитый список категорий для каждой строки в датасете. После этого, если стартап имеет более одной категории, отсортируем локальный список по популярности категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896c00d-5526-4cd3-8dcc-2104fc61e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Перенес в предобработку\n",
    "# category_list_splitted = [item.split('|') for item in df_train.category_list.fillna('').str.lower()]\n",
    "\n",
    "category_list_splitted[:5], len(category_list_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd5d17-02c2-4aa4-b1fd-7b850d59e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Перенес в предобработку\n",
    "# category_counts = Counter(category for sublist in category_list_splitted for category in sublist)\n",
    "\n",
    "category_list_splitted = [[category for category in sorted(sublist, key=lambda x: -category_counts.get(x, 0))] for sublist in category_list_splitted]\n",
    "category_list_splitted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5dbb70-f6fe-4723-aab6-bf1a2f20c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# второе условие - аналог проверки на nan, т.к. выше я использовал fillna('')\n",
    "rows_with_single_cat = pd.Index([i for i, lst in enumerate(category_list_splitted) if (len(lst) == 1) and ('' not in lst)])\n",
    "print('Кол-во стартапов, характеризующихся единственной категорией: ', rows_with_single_cat.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e75f2f-e029-49ff-9eae-d53e6e033753",
   "metadata": {},
   "source": [
    "Добавим новый бинарный признак, характеризующий стартап как многонаправленный или с единственным профилем в зависимости от числа категорий в поле **category_list**. Для тех записей, в которых имеются пропуски в поле category_list, будем назначать категорию, соответствующую единственному профилю. Назовем новое поле **multidisciplinary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f0466-854c-4d82-bbbe-bcb367e7e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['multidisciplinary'] = [False if i in rows_with_single_cat else True for i in df_train.index]\n",
    "df_train['multidisciplinary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412cb3ea-b6e6-4e56-a9fb-c1e979ced6d5",
   "metadata": {},
   "source": [
    "Код для получения данных непосредственно со страницы сайта поддержки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195aa4c9-17d4-4d97-a117-3d307b1cf8c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # URL of the web page\n",
    "# url = 'https://support.crunchbase.com/hc/en-us/articles/360043146954-What-Industries-are-included-in-Crunchbase'\n",
    "\n",
    "# # Initialize a headless browser\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')  # Run in headless mode, no browser window\n",
    "# options.add_argument('--disable-gpu')  # Disable GPU acceleration\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\")\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# # Fetch the HTML content of the web page\n",
    "# driver.get(url)\n",
    "# html_content = driver.page_source\n",
    "\n",
    "# # Close the browser\n",
    "# driver.quit()\n",
    "\n",
    "# # Parse the HTML\n",
    "# soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# # Find the table containing industry groups and industries\n",
    "# table = soup.find('table')\n",
    "\n",
    "# # Initialize an empty dictionary to store industry groups and their corresponding industries\n",
    "# industry_data = {}\n",
    "\n",
    "# # Loop through rows in the table\n",
    "# for row in table.find_all('tr')[1:]:  # Skip the first row (header row)\n",
    "#     # Extract data from cells in the row\n",
    "#     cells = row.find_all('td')\n",
    "#     industry_group = cells[0].text.strip()\n",
    "#     industries = [industry.strip() for industry in cells[2].text.split(',')]\n",
    "    \n",
    "#     # Add industry group and industries to the dictionary\n",
    "#     industry_data[industry_group] = industries\n",
    "\n",
    "# # Print the dictionary\n",
    "# for industry_group, industries in industry_data.items():\n",
    "#     print(f\"{industry_group}: {', '.join(industries)}\")\n",
    "\n",
    "# with open('startup_categories.json', 'w') as json_file:\n",
    "#     json.dump(industry_data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb21f1-4822-4da5-b6b1-74b982ef5dec",
   "metadata": {},
   "source": [
    "Код для получения уже собранного со страницы поддержки файла с моего гитхаба, чтобы код работал на любой системе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2b7d5-f43b-45c3-8fa6-e6dfa8671792",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Lighter01/startups_categories/main/startup_categories.json'\n",
    "\n",
    "local_file_path = './datasets/startup_categories.json'\n",
    "\n",
    "if os.path.exists(local_file_path):\n",
    "    print(\"File already exists.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(local_file_path, 'wb') as json_file:\n",
    "            json_file.write(response.content)\n",
    "        print(\"JSON file downloaded successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download JSON file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce30b1-b91e-488d-b7ea-820038e26923",
   "metadata": {},
   "source": [
    "В связи с тем, что имеются пересечения по категориям стартапов между новыми обобщенными группами, нужно определить однозначное соответствие между категорией и группой. Т.к. вручную проводить анализ каждой категории на соответствие группе не является рациональным решением, упростим задачу. Определим категорию к той группе, в которой она впервые встретилась, а все последующие включения удалим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5abd4b-bc6a-4fbe-bbd8-568616e0c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "with open('./datasets/startup_categories.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "print(sum(len(industries) for industries in data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df844e-441c-4220-b69f-c8524558513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {v.lower().strip(): k.lower().strip() for k, v_list in reversed(data.items()) for v in v_list}\n",
    "len(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618dbea-b9a6-4564-bf20-69da34390097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict['hardware + software'] = 'hardware/software'\n",
    "len(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcceb6-5060-41f3-ab19-7e69a93d47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_categories = list()\n",
    "checked_categories = set()\n",
    "\n",
    "for category_group, category_list in data.items():\n",
    "    for category in category_list:\n",
    "        if category in checked_categories:\n",
    "            duplicated_categories.append((category, category_group))\n",
    "        else:\n",
    "            checked_categories.add(category)\n",
    "\n",
    "duplicated_categories = sorted(duplicated_categories)\n",
    "print('Кол-во дубликатов категорий в различных группах: ', len(duplicated_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f121f1-adb2-4b6b-9aff-ad05c96e57b1",
   "metadata": {},
   "source": [
    "Теперь добавим новый признак - category_group - для обобщения всего разнообразия типов стартапов. Для увеличения шанса найти соответствующую группу, в случае если по главной категории не удастся определить группу, далее будут перебираться другие категории стартапа, если такие имеются, и по первому определенному соответствию будет назначена группа. Категории из списка всех категорий стартапа будут перебираться в порядке уменьшения распостраненности категории. Для всех стартапов, для которых не нашлось соответствующей группы, будем назначать группу 'no_group' по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4868b4d4-8e3a-477e-9a44-18784e8ae968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_category_to_group(row):\n",
    "    if row[0] == '':\n",
    "        return ''\n",
    "    \n",
    "    category = row[0]\n",
    "    if category in cat_dict:\n",
    "        return cat_dict[category]\n",
    "    \n",
    "    category_list = row[1]\n",
    "    for category in category_list:\n",
    "        if category in cat_dict:\n",
    "            return cat_dict[category]\n",
    "    \n",
    "    return 'no_group'\n",
    "\n",
    "vfunc = np.vectorize(map_category_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7474879-9878-4b3a-8f03-2b9b95962966",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('main_category', object), ('category_list', object)]\n",
    "\n",
    "cat_cat_list = np.empty(df_train.shape[0], dtype=dtype)\n",
    "\n",
    "cat_cat_list['main_category'] = df_train['main_category']\n",
    "cat_cat_list['category_list'] = category_list_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaca217-b5b4-4ec7-bf43-d938cd4adc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group = vfunc(cat_cat_list)\n",
    "print('Кол-во записей, для которых не удалось установить группу: ', np.sum(category_group == 'no_group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701865b-e714-457b-b116-99e621505afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_group_id = np.where(category_group == 'no_group')[0]\n",
    "no_group_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096fbd8-9383-4b61-a027-5f30f14bcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cats = np.unique([cat for sublist in cat_cat_list[no_group_id]['category_list'] for cat in sublist])\n",
    "missing_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf61d08-7c6e-4f85-9b09-25125d43b261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.loc[no_group_id, 'status'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1d565-b207-4dd2-ada7-8ad83cf07159",
   "metadata": {},
   "source": [
    "Всего для 6343 записей в тренировочной выборке не удалось определить группу для категории. Анализ этих 6 тысяч записей показал, что из 803 уникальных категорий не нашлось соответствия для 320. Это достаточно много. Однако другой информации о соответствии категории группе не представится, поэтому попробуем решить проблему так. Будем сравнивать оставшиеся неопределенные категории с категориями, для которых имеется соответсвие с группой, сравнивая последовательность символов. Т.е. будем сравнивать строки на близость. Для каждой неопределенной категории найдем максимально схожую категорию из тех, для которой известна группа, и будем присваивать соответствующему стартапу данной категории группу данной наиболее близкой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fbec1-41ca-4290-a961-7412f8732a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cats_list = [sublist for i, sublist in enumerate(category_list_splitted) if i in (no_group_id)]\n",
    "len(missing_cats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d2e48-b470-45e6-992a-596e56c534c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_category_counts = Counter(category for sublist in missing_cats_list for category in sublist)\n",
    "missing_category_counts = sorted(missing_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for key, value in missing_category_counts:\n",
    "    if value > 100:\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286f56a-131b-4eeb-a4a5-bd8c05ebde0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values_map = dict()\n",
    "for missing_cat in missing_cats:\n",
    "    new_key = process.extractOne(missing_cat, cat_dict.keys())\n",
    "    missing_values_map[missing_cat] = cat_dict[new_key[0]]\n",
    "\n",
    "missing_values_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8500a04-d446-491b-b6c1-2ce92d227703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ручные правки\n",
    "missing_values_map['automated kiosk'] = cat_dict['sales automation']\n",
    "missing_values_map['all students'] = 'education'\n",
    "missing_values_map['bridging online and offline'] = 'commerce and shopping'\n",
    "missing_values_map['building products'] = 'real estate'\n",
    "missing_values_map['cars'] = 'transportation'\n",
    "missing_values_map['college campuses'] = cat_dict['college recruiting']\n",
    "missing_values_map['defense'] = 'privacy and security'\n",
    "missing_values_map['discounts'] = 'commerce and shopping'\n",
    "missing_values_map['displays'] = 'consumer electronics'\n",
    "missing_values_map['doctors'] = 'health care'\n",
    "missing_values_map['early-stage technology'] = 'financial services'\n",
    "missing_values_map['english-speaking'] = 'other'\n",
    "missing_values_map['embedded hardware and software'] = 'hardware/software'\n",
    "missing_values_map['entertainment industry'] = 'media and entertainment'\n",
    "missing_values_map['environmental innovation'] = cat_dict['innovation management']\n",
    "missing_values_map['games'] = 'gaming'\n",
    "missing_values_map['gold'] = 'natural resources'\n",
    "missing_values_map['health services industry'] = 'health care'\n",
    "missing_values_map['heavy industry'] = 'manufacturing'\n",
    "missing_values_map['hi tech'] = 'information technology'\n",
    "missing_values_map['high school students'] = 'eduaction'\n",
    "missing_values_map['home owners'] = 'real estate'\n",
    "missing_values_map['human resource automation'] = 'professional services'\n",
    "missing_values_map['iphone'] = 'mobile'\n",
    "missing_values_map['investment management'] = 'financial services'\n",
    "missing_values_map['independent pharmacies'] = 'health care'\n",
    "missing_values_map['reviews and recommendations'] = 'sales and marketing'\n",
    "missing_values_map['self development'] = 'education'\n",
    "missing_values_map['senior health'] = 'health care'\n",
    "missing_values_map['services'] = 'other'\n",
    "missing_values_map['service providers'] = 'professional services'\n",
    "missing_values_map['smart grid'] = 'energy'\n",
    "missing_values_map['television'] = 'media and entertainment'\n",
    "missing_values_map['renewable tech'] = 'other'\n",
    "missing_values_map['specialty foods'] = 'food and beverage'\n",
    "missing_values_map['user experience design'] = cat_dict['ux design']\n",
    "missing_values_map['tracking'] = 'privacy and security'\n",
    "missing_values_map['ventures for good'] = 'food and beverage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9badb-30a6-47a2-9022-1042612249ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group[category_group == 'no_group'] = [missing_values_map[key] for key in cat_cat_list[no_group_id]['main_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c060b-61c9-4168-845e-8f8d46b31dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(category_group == 'no_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29496cb7-b661-4738-936f-fe957edb0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['category_group'] = category_group\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64d864-2bb4-4e5a-a5e0-4a2dc82c72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['category_group'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442e2c9-af46-4dc7-8221-600c6849d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['category_group'].value_counts(ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386add6-337f-4e94-8afd-e34ffe6a1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_groups = df_train['category_group'].value_counts()[df_train['category_group'].value_counts() < 20].keys()\n",
    "df_train.loc[df_train['category_group'].isin(small_groups), 'category_group'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f200c-5035-467f-9c08-fb03faf140fc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db91de8-58e7-4b3c-9b4c-e339e03d2ead",
   "metadata": {},
   "source": [
    "Теперь проделаем те же преобразования для тестовой выборки с некоторыми изменениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68aaf1-662f-40e3-a242-c07bf15284fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list_splitted_test = [item.split('|') for item in df_test.category_list.fillna('').str.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06218a-2cef-407b-895b-145a2f1f16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list_splitted_test = \\\n",
    "    [[category for category in sorted(sublist, key=lambda x: -category_counts.get(x, 0))] for sublist in category_list_splitted_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169613b1-f78c-46c5-a9c5-521875f14500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# второе условие - аналог проверки на nan, т.к. выше я использовал fillna('')\n",
    "rows_with_single_cat = pd.Index([i for i, lst in enumerate(category_list_splitted_test) if (len(lst) == 1) and ('' not in lst)])\n",
    "print('Кол-во стартапов, характеризующихся единственной категорией: ', rows_with_single_cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278bfd2-4b40-4f2b-9d78-0b003121911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['multidisciplinary'] = [False if i in rows_with_single_cat else True for i in df_test.index]\n",
    "df_test['multidisciplinary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa343d60-ea15-4d9b-bb75-ca830e92656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cat_list = np.empty(df_test.shape[0], dtype=dtype)\n",
    "\n",
    "cat_cat_list['main_category'] = df_test['main_category']\n",
    "cat_cat_list['category_list'] = category_list_splitted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a755024-f935-475b-9c88-0046f7290e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group = vfunc(cat_cat_list)\n",
    "print('Кол-во записей, для которых не удалось установить группу: ', np.sum(category_group == 'no_group'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db896f65-df85-416e-ae59-4fc5c9fd9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_group_id = np.where(category_group == 'no_group')[0]\n",
    "no_group_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14325cd-6048-4ca3-baae-00f8206285ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cats = np.unique([cat for sublist in cat_cat_list[no_group_id]['category_list'] for cat in sublist])\n",
    "missing_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbcc3d-fa7b-45dc-b53e-4c98b2ecffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[no_group_id, 'status'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d3a95-4378-49f5-b93d-775d01820b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cats_list = [sublist for i, sublist in enumerate(category_list_splitted_test) if i in no_group_id]\n",
    "len(missing_cats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d9f75-36b6-436e-9708-fcb18d1b0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_category_counts = Counter(category for sublist in missing_cats_list for category in sublist)\n",
    "missing_category_counts = sorted(missing_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for key, value in missing_category_counts:\n",
    "    if value > 30:\n",
    "        print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad65107-b9a4-4655-9fdb-767a337a414f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values_map = dict()\n",
    "for missing_cat in missing_cats:\n",
    "    new_key = process.extractOne(missing_cat, cat_dict.keys())\n",
    "    missing_values_map[missing_cat] = cat_dict[new_key[0]]\n",
    "\n",
    "missing_values_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d9a0e-a49a-4952-a49c-b7e997e3ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group[category_group == 'no_group'] = [missing_values_map[key] for key in cat_cat_list[no_group_id]['main_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26798de3-44af-4bdd-bad0-941d61b51a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(category_group == 'no_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1886594-d0f3-4226-b89f-5a0f38c2eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group[no_group_id[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b38c0-621b-40bb-9a9b-6d6838b04ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['category_group'] = category_group\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47725f66-e55b-4361-90ef-3e8d892b8ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test['category_group'].value_counts(ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eaf9ad-c565-48b1-bc1b-e9f5abaf0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_groups = df_test['category_group'].value_counts()[df_test['category_group'].value_counts() < 20].keys()\n",
    "df_test.loc[df_test['category_group'].isin(small_groups), 'category_group'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ecf18-afc4-4023-8a00-8a88c10505a4",
   "metadata": {},
   "source": [
    "Удалим наконец колонку \"category_list\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039f6b0-b878-45c8-b8e5-fdee8a990462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['category_list'])\n",
    "df_test  = df_test.drop(columns=['category_list'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412a984-579a-4bab-933f-6bffda7ccc06",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ee02f-d857-49de-ad47-433013655c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_map_tmp = dict()\n",
    "\n",
    "# for missing_cat in missing_cats:\n",
    "#     new_key_1 = process.extractOne(missing_cat, cat_dict.keys())\n",
    "#     new_key_2 = process.extractOne(missing_cat, cat_dict.keys(), scorer=fuzz.token_set_ratio)\n",
    "#     missing_values_map_tmp[missing_cat] = (new_key_1[0], new_key_2[0])\n",
    "\n",
    "# df_missing_values_info_tmp = pd.DataFrame.from_dict(missing_values_map_tmp, orient='index', columns=['without_scorer', 'with_set_scorer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e67c8-d78b-43e4-9407-8eb56fc31469",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c204931-3a7d-4df3-9486-598701983b05",
   "metadata": {},
   "source": [
    "### funding_total_usd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9ee45-ca4a-4c6f-aa19-3dc06f0a0058",
   "metadata": {},
   "source": [
    "Проведем лог-преобразование, как делали это ранее в исследовательском анализе, но в этот раз уже сохраним преобразование в датасетах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f340c8e-b9da-48ee-8458-23fc72b35da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_funding_total_usd'] = np.log(df_train['funding_total_usd'])\n",
    "df_test['log_funding_total_usd']  = np.log(df_test['funding_total_usd'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff771f13-bfa5-46f3-80c3-eff42eb95580",
   "metadata": {},
   "source": [
    "Добавим еще один признак - среднюю сумму инвестиций. Данный признак будет сильно коррелировать с признаком funding_total_usd, т.к. более половины всех записей - о стартапах, у которых было проведено не более одного раунда финансирования. На этапе корреляционного анализа сравним корреляцию нового признака и funding_total_usd с целевым параметром и выберем тот, который будет более информативным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c03d1c-7bdb-4f42-9bab-7a2b5548ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mean_funding_sum'] = df_train['funding_total_usd'] / df_train['funding_rounds']\n",
    "df_test['mean_funding_sum']  = df_test['funding_total_usd'] / df_test['funding_rounds']\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96b6e6-11ef-42f3-8bdc-89af3529bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec92172-c791-4d4a-9809-7147f564d736",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe101e-07f0-4e8c-8858-9ba09927c9af",
   "metadata": {},
   "source": [
    "### founded_at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2cfa90-65b6-4aa6-98b5-88d041ee8334",
   "metadata": {},
   "source": [
    "Выделим отдельно новый признак - год основания стартапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816bee0-8bb0-4552-bb1f-b31bebe093e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['foundation_year'] = df_train['founded_at'].dt.year\n",
    "df_test['foundation_year']  = df_test['founded_at'].dt.year\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a283d3-280a-4452-b573-a7cca3b77538",
   "metadata": {},
   "source": [
    "Добавим бинарный признак - был ли стартап основан до своего первого раунда финансирования или после."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a83672-a2f7-4f87-9570-edb5f192991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['funded_before_founding'] = df_train['founded_at'] > df_train['first_funding_at']\n",
    "df_test['funded_before_founding']  = df_test['founded_at']  > df_test['first_funding_at']\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647c386-cdfa-464c-b0d3-9b3edde036ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['funded_before_founding']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473c35f-fc59-4abf-9816-d6a816c69aca",
   "metadata": {},
   "source": [
    "Также, для целостности картины, добавим и признак \"время между созданием стартапа и первым раундом финансирования\". Такой признак скорее всего будет сильно коррелировать с новым признаком funded_before_founding, но funded_before_founding - бинарный признак, а создаваемый - дискретный. Потенциально такой признак может содержать больше информации в себе, но это проверим на этапе корреляционного анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd18caa-0e91-4ccc-9f9a-05184f7a8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['first_funding_after_foundation'] = df_train['first_funding_at'] - df_train['founded_at']\n",
    "df_test['first_funding_after_foundation']  = df_test['first_funding_at']  - df_test['founded_at']\n",
    "\n",
    "df_train['first_funding_after_foundation'] = df_train['first_funding_after_foundation'].dt.days\n",
    "df_test['first_funding_after_foundation']  = df_test['first_funding_after_foundation'].dt.days\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c3b98-e3ce-4c28-b490-3fca2c8626cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e2d0c-21e1-485c-8320-a9b4807026cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=df_train, x=\"foundation_year\", y=\"first_funding_after_foundation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37b2f7-a834-49a2-a0e3-0792c96fc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['first_funding_after_foundation'] < 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1b964-5770-46e2-b5d0-b95cea0d52ae",
   "metadata": {},
   "source": [
    "Следующий признак предположительно будет коррелировать с признаком **funding_rounds**, поэтому пока добавим его, а на этапе корреляционного анализа решим, оставить его или удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf28261b-9f59-4474-8c01-1660290e080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['first_last_funding_gap'] = df_train['last_funding_at'] - df_train['first_funding_at']\n",
    "df_train['first_last_funding_gap'] = df_train['first_last_funding_gap'].dt.days\n",
    "\n",
    "df_test['first_last_funding_gap']  = df_test['last_funding_at']  - df_test['first_funding_at']\n",
    "df_test['first_last_funding_gap']  = df_test['first_last_funding_gap'].dt.days\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28108e-ea2c-4a2d-a9f9-822bcafa5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32c64d-5c21-4dba-a39e-7aef5cd9d461",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c901826-4a2c-422d-a549-fb577fba15a0",
   "metadata": {},
   "source": [
    "### region, city, state_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872de56f-33d1-487e-821f-fe20eb155304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно добавить бинарный признак с информацией о городе, \n",
    "# в котором был создан стартапа, если это крупный город, \n",
    "# вроде Нью-Йорка или Лондона. Аналогично можно сделать что-то с самыми успешными штатами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7035f-b90f-46ed-974b-1b1e196a1f51",
   "metadata": {},
   "source": [
    "Удалим малоинформативные и слишком разнообразные кат. признаки \"регион\" и \"город\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b6e28-1a45-4ff4-917e-0108a2bad56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['region', 'city', 'state_code'])\n",
    "df_test  = df_test.drop(columns=['region', 'city', 'state_code'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1149d-bbd0-4cb2-96b5-74ab6af133e5",
   "metadata": {},
   "source": [
    "Добавим новые признаки - континент стартапа и субрегион."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0ea87-18cc-4a97-877e-3c49c8bdb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Lighter01/startups_categories/main/countryContinent.csv'\n",
    "\n",
    "local_file_path = './datasets/countryContinent.csv'\n",
    "\n",
    "if os.path.exists(local_file_path):\n",
    "    print(\"File already exists.\")\n",
    "else:\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open('./datasets/countryContinent.csv', 'wb') as csv_file:\n",
    "            csv_file.write(response.content)\n",
    "        print(\"CSV file downloaded successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c593850-2b0a-4928-b829-7b04abff8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = pd.read_csv('./datasets/countryContinent.csv', sep=',', encoding='cp1252').drop(columns=['country_code'])\n",
    "continents = continents.rename(columns={\"code_3\": \"country_code\"})\n",
    "continents.loc[continents['country'] == 'Romania', 'country_code'] = 'ROM'\n",
    "continents.loc[continents['country'] == 'Bahamas', 'country_code'] = 'BAH'\n",
    "continents = continents[['country_code', 'continent', 'sub_region']]\n",
    "continents.loc[continents.shape[0]] = ['TAN', 'Africa', 'Eastern Africa']\n",
    "\n",
    "df_train = df_train.join(continents.set_index('country_code'), on='country_code')\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05d221-47f9-48db-b6fd-f9579b605483",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train[(df_train['country_code'].notna()) & (df_train['continent'].isna())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b287b6ad-2244-4692-a6f1-e2254247d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['country_code'].isna().sum(), df_train['continent'].isna().sum(), df_train['sub_region'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a345b0f-2dc2-4083-b1ae-bfc815bc954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['continent'].value_counts(), df_train['sub_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8026c8-ea2a-42f5-be1a-5d363836cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.join(continents.set_index('country_code'), on='country_code')\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179affa-00f8-4dd9-bea6-50287a74bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_test[(df_test['country_code'].notna()) & (df_test['continent'].isna())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfb8f7-1f6e-4566-a11c-fefe099df17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['country_code'].isna().sum(), df_test['continent'].isna().sum(), df_test['sub_region'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740778ca-afc4-4738-8ae5-2ef41b81eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['continent'].value_counts(), df_test['sub_region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce991bad-53ec-4efd-847d-67a04993688d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a7f70-dbb8-46ef-a460-52ea76d04e6e",
   "metadata": {},
   "source": [
    "### Даты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dcf35b-1c77-4caa-a594-bc5295f97ce2",
   "metadata": {},
   "source": [
    "Удалим все признаки, связанные с датами. Во-первых, признак **founded_at** был упрощен до года создания стартапа. Во-вторых, **first_funding_at** и **last_funding_at** были преобразованы в новые признаки - кол-во дней между созданием стартапа и первым финансированием и бинарный признак, был ли стартап создан до или после своего первого финансирования. **closed_at** вообще никак нельзя сохранять, так как это признак, напрямую связанный с целевым параметром, а стоящая задача заключается в том, чтобы предсказывать состояние стартапа в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637996d-2963-4df0-9009-f855899d0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "df_test  = df_test.drop(columns=['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'])\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd74aa-e066-4e29-a5b8-bd42ad879409",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4767758-c760-4c60-9e53-3d04a4386b05",
   "metadata": {},
   "source": [
    "# Корреляционный анализ и отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ae0ca-a6d6-4f61-90be-726310aa2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a613c3-374f-4f41-96b7-eabf9b89eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cor_mat(correlation_matrix, mask=True, colormap='coolwarm', params={}):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    if mask:\n",
    "        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap=colormap, fmt='.2f', cbar_kws={\"shrink\": 0.75}, annot_kws={\"fontsize\": \"small\"}, **params)\n",
    "    else:\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap=colormap, fmt='.2f', cbar_kws={\"shrink\": 0.75}, annot_kws={\"fontsize\": \"small\"})\n",
    "        \n",
    "    plt.title('Phi-K correlation matrix')\n",
    "    plt.tick_params(axis='x', labelsize=12)\n",
    "    plt.tick_params(axis='y', labelsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d8506-fe7d-4eb4-bdf2-8e43eaa3c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phik\n",
    "interval_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print('Interval columns: ', interval_cols)\n",
    "\n",
    "correlation_matrix = df_train.phik_matrix(interval_cols=interval_cols, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14a11f-bddf-4877-85b8-4e80c032da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cor_mat(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a724d-e422-49f0-9102-0140ac1aa7d6",
   "metadata": {},
   "source": [
    "- Из географических признаков оставим один. Пусть это будет параметр **continent**. Хоть номинально country_code коррелирует сильнее с целевой переменной, но это достигается за счет большего числа уникальных значений данного признака. Т.е. размеры выборки по каждой стране, во-первых, меньше, а во-вторых, их размеры распределены неравномерно. Группировка стран по географическому признаку создаст более крупные обобщенные группы, увеличит подвыборки, самих групп будет меньше, но при этом они всё еще будут содержать информацию о своих странах. sub_region выбирать не будем, т.к. sub_region разбивает записи на немного большее число групп, что приводит к образованию классов, в которые входят всего одна-две страны.\n",
    "- Признак **mean_funding_sum** оказался неудачным, т.к. почти совсем не помогает разделить целевой показатель на два класса. Кроме того он, очевидно, коррелирует с **funding_total_usd**, что скорее всего связано с тем, что в выборке находится очень много записей о стартапах, у которых был всего один раунд финансирования. Корреляции с целевым параметром у обоих признаков не обнаружено. Поэтому удалим эти два признака, оставив последний признак, содержащий информацию о доходах стартапов - **log_funding_total**. Данный параметр имеет слабую корреляцию с целевой переменной и имеет среднюю информационную ценность по mutual_info и ANOVA.\n",
    "- Признаки **first_funding_after_foundation** и **foundation_year** имеют сильную линейную связь, при этом каждый из признаков по отдельности довольно информативен, хоть и имеет слабую корреляцию с целевой переменной. Оставим все же first_funding_after_foundation, т.к. хоть корреляция более сильная у foundation_year, но у параметра года основания очень плохая интерпретируемость, т.е. сам по себе параметр позволит скорее идентифицировать более успешные года в целом, что позволит придерживаться логики, что в среднем если в году было больше удачных стартапов, то и одного конкретного шансы выше. first_funding_after_foundation в этом плане является более универсальным параметром, описывающим скорее скорее поведенческую черту стартапа, нежели какую-то статическую характеристику (очень запутанно, извините).\n",
    "- category_group и main_category имеют идеальную корреляцию, т.к. один признак был порожден другим, т.е. имеется однозначеное отображение из одного пространства признаков в другое. В данном случае мне сложно выбрать что-то одно. Поэтому выберу один из признаков с расчетом, что в случае необходимости можно будет переобучить модель на другой подвыборке признаков. На  данный момент оставим признак **category_group**, т.к. он является более компактным признаком, включающим значительно меньше классов, нежели признак main_category.\n",
    "- Признаки **funding_rounds**, **first_last_funding_gap** и **multidisciplinary** оставим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5eadb0-9e69-40ea-8ad6-96c9fc0260bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "significance_overview = df_train.significance_matrix(interval_cols=interval_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c25fe6-b25b-454d-a0ff-1e3127175c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cor_mat(significance_overview, colormap=sns.color_palette(\"light:#5A9\", as_cmap=True), params={\"vmin\":-5, \"vmax\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec682a-1a23-48da-8623-1344bf3f0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_train.dropna()\n",
    "\n",
    "X, y = df_tmp.drop(columns=['status']), df_tmp['status']\n",
    "discrete_features = ((X.dtypes == 'int64') | (X.dtypes == int))\n",
    "for colname in X.select_dtypes(\"object\"):\n",
    "    X[colname], _ = X[colname].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec22ebf-f81f-4630-bcb3-db99def6e403",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# selector = SelectKBest(lambda x, y: mutual_info_classif(x, y, discrete_features=discrete_features) , k=1)\n",
    "# X_reduced = selector.fit_transform(X, y)\n",
    "\n",
    "# cols = selector.get_support(indices=True)\n",
    "# selected_columns = X.iloc[:,cols].columns.tolist()\n",
    "# selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172a4a2-c1de-4293-a9b1-8a6e60158969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f945b9-b269-4642-a234-2529322fdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, title=''):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_scores(mi_scores, title=\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122e881-5fb2-4995-ad2a-a16264996999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_f_scores(X, y):\n",
    "    F_scores, pvalues = f_classif(X, y)\n",
    "    F_scores = pd.Series(F_scores, name=\"F Scores\", index=X.columns)\n",
    "    F_scores = F_scores.sort_values(ascending=False)\n",
    "    return F_scores, pvalues\n",
    "\n",
    "F_scores, pvalues = make_f_scores(X, y)\n",
    "F_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bbce3-ec1c-4427-897b-ae79fc925eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(F_scores, title=\"F Scores\")\n",
    "display(pd.DataFrame(data={'F Scores': F_scores, 'p values': pvalues}).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9ed58-7f1d-4f46-8037-807efe805fb2",
   "metadata": {},
   "source": [
    "Удаляем все ненужные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19871281-5aab-43a4-bd43-8695976c5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train.drop(columns=['funding_total_usd', 'country_code', 'sub_region',\n",
    "                                        'mean_funding_sum', 'foundation_year', 'main_category'])\n",
    "df_test_final  = df_test.drop(columns =['funding_total_usd', 'country_code', 'sub_region',\n",
    "                                        'mean_funding_sum', 'foundation_year', 'main_category'])\n",
    "\n",
    "df_train_final.shape, df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538353e-55e4-4a29-942e-2c2286ce0a4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(df_train_final, dimensions=df_train_final.select_dtypes(include=[int, float]).columns, color='status')\n",
    "\n",
    "fig.update_layout(\n",
    "    title='',\n",
    "    width=1050, \n",
    "    height=1050,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bda04b-bea6-40b3-90e5-c719f13f8d0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83cd81-9379-40a5-a549-204d6fb75950",
   "metadata": {},
   "source": [
    "# Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9bab52-c16c-4b90-b844-782132fcfbef",
   "metadata": {},
   "source": [
    "Преобразуем все категориальные признаки к типу \"category\", потому что модели, которые будут использованы позже, предпочитают работать с этим типом категориальной переменной.\n",
    "Также заменим в категориальных столбцах пустые строки на nan.\n",
    "\n",
    "Для заполнения пропусков воспользуемся библиотекой miceforest, реализующей алгоритм заполнения пропусков MICE. В качестве базовой модели, используемой для промежуточных предсказаний на итерациях, используется LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed55af6-ba95-42fc-8463-7ed7da8f768a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = df_train_final.select_dtypes(include=['object']).columns\n",
    "df_train_final[cat_cols] = df_train_final[cat_cols].astype('category')\n",
    "df_train_final = df_train_final.replace('', np.nan)\n",
    "df_train_final.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753577ab-09c4-4d2f-82e5-fb2ccf752715",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df_test_final.select_dtypes(include=['object']).columns\n",
    "df_test_final[cat_cols] = df_test_final[cat_cols].astype('category')\n",
    "df_test_final = df_test_final.replace('', np.nan)\n",
    "df_test_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b57b43-35d8-4c6b-a5cf-95beeb1ffc15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_nans(df_train_final)\n",
    "display_nans(df_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2080b3-cb66-469f-bdf9-9eb484aea944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplots(df, target=''):\n",
    "    val_cols = df.select_dtypes(include=[int, float]).columns\n",
    "    # cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    tar_col = df[target]\n",
    "    \n",
    "    for val_col in val_cols:\n",
    "        scatter_fig = px.scatter(df, x=val_col, y=tar_col, trendline=\"ols\", trendline_color_override=\"red\")\n",
    "        scatter_fig.update_layout(title=f'')\n",
    "        \n",
    "        scatter_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a85e1-4ac4-4249-80b5-3bf6f7fb01f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_scatterplots(df_train_final, 'log_funding_total_usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3f122-78fd-450b-86ab-e7bc4c19b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(X):\n",
    "    scheme_mmc = mean_match_default.copy()\n",
    "    scheme_mmc.set_mean_match_candidates(0) # замена 0 на любое другое число приводит к ошибке.\n",
    "    \n",
    "    # categorical_features = X.select_dtypes(include=['category']).columns.to_list()\n",
    "    \n",
    "    kernel = mf.ImputationKernel(\n",
    "        X,\n",
    "        mean_match_scheme = scheme_mmc, \n",
    "        datasets = 1,\n",
    "        # categorical_feature = categorical_features,\n",
    "        random_state=RANDOM_STATE\n",
    "    )    \n",
    "\n",
    "    variable_parameters = {\n",
    "      'log_funding_total_usd': {\n",
    "          \"objective\": \"regression\",\n",
    "          \"metric\": \"rmse\"\n",
    "      },\n",
    "      'continent': {\n",
    "          'objective': 'multiclass',\n",
    "          'metric': 'multi_logloss' # multi_error\n",
    "      },\n",
    "      'category_group': {\n",
    "          'objective': 'multiclass',\n",
    "          'metric': 'multi_logloss' # multi_error\n",
    "      }\n",
    "    }\n",
    "        \n",
    "    kernel.mice(\n",
    "        iterations = 5,\n",
    "        num_boost_round = 125,\n",
    "        max_bin = 32,\n",
    "        boosting = 'gbdt',\n",
    "        variable_parameters = variable_parameters,\n",
    "        min_data_in_leaf=10\n",
    "    )\n",
    "\n",
    "    return kernel.complete_data(dataset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d288dc-6193-437a-afb2-30728170a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = df_train_final.drop(columns=['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58492d0-37ea-470a-816a-1bdbaad10e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tmp.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963fe09c-af24-48a7-b7f8-2bec15694721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tmp_imp = imputer(X_tmp)\n",
    "X_tmp_imp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fa193-8eab-4cc9-a402-6f6fcb195f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final_imputed = X_tmp_imp\n",
    "del X_tmp_imp\n",
    "df_train_final_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2a689-bbc4-4b80-b763-d3e27dc55961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final_imputed['status'] = df_train_final['status']\n",
    "df_train_final = df_train_final_imputed\n",
    "del df_train_final_imputed\n",
    "\n",
    "df_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b849c7-caea-4ae1-9759-999a1abbce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_final.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d4aaf-8800-40a6-8543-d6cb52fdf2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_final = imputer(df_test_final)\n",
    "df_test_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0116a5-ad83-4e36-82f0-e080197b5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final[['funding_rounds', 'first_funding_after_foundation', 'first_last_funding_gap']] = \\\n",
    "    df_train_final[['funding_rounds', 'first_funding_after_foundation', 'first_last_funding_gap']].astype('int64')\n",
    "\n",
    "df_train_final[['category_group', 'continent']] = df_train_final[['category_group', 'continent']].astype('category')\n",
    "\n",
    "df_train_final['log_funding_total_usd'] = df_train_final['log_funding_total_usd'].astype('float64')\n",
    "\n",
    "df_train_final[['multidisciplinary', 'funded_before_founding']] = df_train_final[['multidisciplinary', 'funded_before_founding']].astype(bool)\n",
    "\n",
    "df_train_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e2baf-d082-4b6b-8833-68a8a8487560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final[['funding_rounds', 'first_funding_after_foundation', 'first_last_funding_gap']] = \\\n",
    "    df_test_final[['funding_rounds', 'first_funding_after_foundation', 'first_last_funding_gap']].astype('int64')\n",
    "\n",
    "df_test_final[['category_group', 'continent']] = df_test_final[['category_group', 'continent']].astype('category')\n",
    "\n",
    "df_test_final['log_funding_total_usd'] = df_test_final['log_funding_total_usd'].astype('float64')\n",
    "\n",
    "df_test_final[['multidisciplinary', 'funded_before_founding']] = df_test_final[['multidisciplinary', 'funded_before_founding']].astype(bool)\n",
    "\n",
    "df_test_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33aaa0-2916-4f2a-9f2b-52dfb9feb20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nans(df_train_final)\n",
    "display_nans(df_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af403b-5e5d-4223-bebe-790fa1eadecf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e69154-3243-476f-b5cd-3748200f4442",
   "metadata": {},
   "source": [
    "# Подготовка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f1b52-0317-4cca-8df9-c55bbd03b727",
   "metadata": {},
   "source": [
    "В рамках данной работы упор будет сделан на модели градиентного бустинга на деревьях решений. Вначале обучим простой случайный лес, после чего перейдем к двум современным представителям градиентных моделей - XGBoost и LightGBM. Обучаться модели будут с применением Optuna - фреймворка для оптимизации гиперпараметров, использующего в своей основе байесовскую оптимизацию. В конце выберем одну модель, которая продемонстрирует самые высокие показатели целевой метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899eafd9-dc59-4e03-8eb9-68ce6320b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_size(df_train_final, 'status', labels='', explode=(0, 0.05), palette=sns.color_palette('Set2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e81222-1d88-4f81-b896-e37744386707",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = df_train_final.drop(columns=['status']), df_train_final['status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, shuffle=True, stratify=y, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227bbb2-d4d8-4fbc-ba82-212357ed6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampling = SMOTE(random_state=RANDOM_STATE)\n",
    "# X_train_smote, y_train_smote = upsampling.fit_resample(X_train, y_train)\n",
    "# X_train_smote.shape, y_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa1606-366f-4792-8362-586f3426d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c5cee-26ee-4180-b023-aaca27a066cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "numerical_features   = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa3b0d-6aa1-4ffa-bb2c-61ab549e9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline с применением SMOTENC, не требует кодировки кат. признаков перед применением апсемплера\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "                transformers = [\n",
    "                    ('std_scaler', StandardScaler(), numerical_features[1:]),\n",
    "                    ('target_encoder', TargetEncoder(random_state=RANDOM_STATE, target_type='binary'), ['category_group']),\n",
    "                    ('ohe', OneHotEncoder(drop='first', sparse_output=False), ['multidisciplinary', 'funded_before_founding', 'continent']),\n",
    "                ],\n",
    "                remainder='passthrough'\n",
    "            ).set_output(transform='pandas')\n",
    "\n",
    "smotenc = SMOTENC(categorical_features=categorical_features,\n",
    "                  random_state=RANDOM_STATE, \n",
    "                  sampling_strategy=0.75)\n",
    "rand_downsampler = RandomUnderSampler(sampling_strategy=0.8, random_state=RANDOM_STATE)\n",
    "\n",
    "preprocessor_nc = imbpipeline(\n",
    "                    steps = [\n",
    "                        ('umsampling', smotenc),\n",
    "                        ('downsampling', rand_downsampler),\n",
    "                        ('transforming', transformer)\n",
    "                    ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fb45f-9f95-4e5b-ab76-6bc8ba1d65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective_fn(trial, X, y):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":      trial.suggest_int('n_estimators', 128, 512, step=32),\n",
    "        \"max_depth\":         trial.suggest_int('max_depth', 3, 8),\n",
    "        \"criterion\":         trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "        \"max_features\":      trial.suggest_categorical('max_features', [None, 'sqrt', 'log2']),\n",
    "        \"min_samples_split\": trial.suggest_int('min_samples_split', 2, 150),\n",
    "        \"min_samples_leaf\":  trial.suggest_int('min_samples_leaf', 1, 60),\n",
    "        \"bootstrap\":         trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    if params['bootstrap']:\n",
    "        params['max_samples'] = trial.suggest_float('max_samples', 0.6, 1, step=0.1)\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=862, n_jobs=3, **params)\n",
    "\n",
    "    model_pipeline = imbpipeline(\n",
    "                        steps = [\n",
    "                            ('umsampling', smotenc),\n",
    "                            ('downsampling', rand_downsampler),\n",
    "                            ('transforming', transformer),\n",
    "                            ('fitting', model)\n",
    "                        ]\n",
    "                       )\n",
    "    \n",
    "    cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=862)\n",
    "    scoring = {\n",
    "        'f1_score': make_scorer(f1_score, average='binary', pos_label='closed'),\n",
    "    }\n",
    "    cv_scores = cross_validate(model_pipeline, X, y, n_jobs=5, cv=cross_val, scoring=scoring, error_score='raise')\n",
    "    \n",
    "    scores = []\n",
    "    for metric in scoring.keys():\n",
    "        scores.append(np.mean(cv_scores['test_' + metric]))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Trial {trial.number} elapsed time:\", end_time - start_time, \"seconds\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e276b5a-9542-419c-838d-5ee55740cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_study = optuna.create_study(directions=[\"maximize\"], sampler=optuna.samplers.TPESampler(seed=862))\n",
    "rf_study.optimize(lambda trial: rf_objective_fn(trial, X_train, y_train), n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a9d2e5-0c18-42a5-99a9-496507750480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_objective_fn(trial, X, y):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # dX_matrix = xgb.DMatrix(X, y)\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":       trial.suggest_int('n_estimators', 128, 512, step=32),\n",
    "        \"max_depth\":          trial.suggest_int('max_depth', 3, 8),\n",
    "        \"learning_rate\":      trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        \"subsample\":          trial.suggest_float('subsample', 0.6, 1.0, step=0.1),\n",
    "        \"colsample_bytree\":   trial.suggest_float('colsample_bytree', 0.4, 1),\n",
    "        # \"lambda\":            trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # \"alpha\":             trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True)\n",
    "        \"lambda\":             trial.suggest_float(\"lambda\", 1e-3, 10.0, log=True),\n",
    "        \"alpha\":              trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "        # \"enable_categorical\": True # Мусор без DMatrix\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                              device='cuda',\n",
    "                              tree_method='hist',\n",
    "                              seed=862,\n",
    "                              **params\n",
    "    )\n",
    "\n",
    "    model_pipeline = imbpipeline(\n",
    "                        steps = [\n",
    "                            ('umsampling', smotenc),\n",
    "                            ('downsampling', rand_downsampler),\n",
    "                            ('transforming', transformer),\n",
    "                            ('fitting', model)\n",
    "                        ]\n",
    "                       )\n",
    "    \n",
    "    cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=862)\n",
    "    scoring = {\n",
    "        'f1_score': make_scorer(f1_score, average='binary', pos_label=1),\n",
    "    }\n",
    "    cv_scores = cross_validate(model_pipeline, \n",
    "                               X, \n",
    "                               [int(stat == 'closed') for stat in y], \n",
    "                               n_jobs=5, cv=cross_val, scoring=scoring, error_score='raise')\n",
    "    \n",
    "    scores = []\n",
    "    for metric in scoring.keys():\n",
    "        scores.append(np.mean(cv_scores['test_' + metric]))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Trial {trial.number} elapsed time:\", end_time - start_time, \"seconds\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e727c4f-9741-4e03-ac4c-d08347037228",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_study = optuna.create_study(directions=[\"maximize\"], sampler=optuna.samplers.TPESampler(seed=862))\n",
    "xgb_study.optimize(lambda trial: xgb_objective_fn(trial, X_train, y_train), n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053b72c-5ec4-49d2-bb19-3fce3200dd9b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcac830-2525-4bd7-892d-0008457e36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective_fn(trial, X, y):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"max_bin\": 32,\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"num_boost_round\": trial.suggest_int(\"num_boost_round\", 100, 500),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, device='cpu')\n",
    "\n",
    "    model_pipeline = imbpipeline(\n",
    "                        steps = [\n",
    "                            ('umsampling', smotenc),\n",
    "                            ('downsampling', rand_downsampler),\n",
    "                            ('transforming', transformer),\n",
    "                            ('fitting', model)\n",
    "                        ]\n",
    "                       )\n",
    "    \n",
    "    cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=862)\n",
    "    scoring = {\n",
    "        'f1_score': make_scorer(f1_score, average='binary', pos_label=1),\n",
    "    }\n",
    "    cv_scores = cross_validate(model_pipeline, \n",
    "                               X, \n",
    "                               [int(stat == 'closed') for stat in y], \n",
    "                               n_jobs=5, cv=cross_val, scoring=scoring, error_score='raise')\n",
    "    \n",
    "    scores = []\n",
    "    for metric in scoring.keys():\n",
    "        scores.append(np.mean(cv_scores['test_' + metric]))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Trial {trial.number} elapsed time:\", end_time - start_time, \"seconds\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0362e-8af1-449a-b75f-a8ecb68ed593",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study = optuna.create_study(directions=[\"maximize\"], sampler=optuna.samplers.TPESampler(seed=862))\n",
    "lgb_study.optimize(lambda trial: lgb_objective_fn(trial, X_train, y_train), n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54977b5-cfe1-49d6-b3d2-8781fb23fe0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e489392-1abd-443b-bce8-caa84bf6b1f3",
   "metadata": {},
   "source": [
    "# Анализ лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349c51a-ca58-4b49-9789-094e42caba22",
   "metadata": {},
   "source": [
    "Итак, лучше всего себя показала модель классификации XGBoost. Теперь рассмотрим данную модель подробнее, проанализируем важность признаков для нее,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f23d1-5dcf-4575-acc6-63ebe06ed692",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(**xgb_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a368cd-bf50-4ad6-be2e-9999bd6e242c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pipeline = imbpipeline(\n",
    "                        steps = [\n",
    "                            ('umsampling', smotenc),\n",
    "                            ('downsampling', rand_downsampler),\n",
    "                            ('transforming', transformer),\n",
    "                            ('fitting', xgb_clf)\n",
    "                        ]\n",
    "                       )\n",
    "model_pipeline.fit(X_train, [1 if status=='closed' else 0 for status in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07d1f7-c077-4d01-ae3a-84845ae8ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show = pd.DataFrame(xgb_clf.feature_importances_, columns=['Feature Importance'], index=xgb_clf.feature_names_in_).sort_values(by='Feature Importance', ascending=False)\n",
    "display(df_show.style.background_gradient(cmap='Blues'))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "y_pos = np.arange(len(df_show))\n",
    "\n",
    "ax.barh(df_show.index[::-1], df_show['Feature Importance'][::-1], alpha=0.8, edgecolor='black', linewidth=1)\n",
    "ax.set_xlabel('Feature Importance', fontsize=14)\n",
    "ax.set_title('Feature Importance for each column', fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "ax.grid(axis='x', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd00b58-9d8b-462e-8fdf-c2ace2a96931",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = model_pipeline.named_steps['fitting']\n",
    "umsampler_xgb   = model_pipeline.named_steps['umsampling']\n",
    "downsample_xgb  = model_pipeline.named_steps['downsampling']\n",
    "transformer_xgb = model_pipeline.named_steps['transforming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf51d50-3cf5-43d7-95d8-5d722fb5e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification(model, X, y, title=''):\n",
    "    y_pred = model.predict(transformer_xgb.transform(X))\n",
    "    y_pred = ['closed' if status == 1 else 'operating' for status in y_pred]\n",
    "\n",
    "    print(f'Accuracy: {accuracy_score(y, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y, y_pred, pos_label='closed')}')\n",
    "    print(f'Recall: {recall_score(y, y_pred, pos_label='closed')}')\n",
    "    print(f'F1: {f1_score(y, y_pred, pos_label='closed')}')\n",
    "\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['closed', 'operating']).plot()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636de830-1d30-41d8-ba39-4ece88e483a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification(xgb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed273149-4c85-4898-a90a-27febfaab598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transformer_xgb.transform(downsample_xgb.fit_resample(*umsampler_xgb.fit_resample(X_test, y_test))[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758fe04-ae92-45ed-aba7-bc465d90577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ind = data.reset_index().sample(n=75, random_state=RANDOM_STATE).index\n",
    "sample_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86a52e-c5be-450f-b179-08cd33a99aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_clf)\n",
    "shap_values = explainer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ff26a-a76a-42c8-864b-ddbab2d27192",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4ebd8-9323-4f7e-9093-d3fdc8c5072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(explainer.expected_value, shap_values.values[sample_ind, :], feature_names=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ec59d-c6e2-4c4d-8c20-b38c479266ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(explainer.expected_value, shap_values.values[862, :], feature_names=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383a26f-3fa0-41e1-b8f2-8238c4a978ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(explainer.expected_value, shap_values.values[850, :], feature_names=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1069c0-5f86-4dbd-b899-dd92d2fab6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[862, :], max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae754a9-ff13-4422-85e5-36d53b01417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[850, :], max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce7ec4-7307-4957-b187-99b1e97de9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080c164-cfad-4b57-bee2-910fbdb08f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values) # summary_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d361b2-21e6-4a17-92b6-0d854f12d966",
   "metadata": {},
   "source": [
    "Лучшей моделью среди рассмотренных оказался модель градиентного бустинга на решающими деревьями - XGBoost. Итоговая модель имеет далеко не самые выдающиеся результаты - всего 0.227 по F1.\n",
    "\n",
    "Анализ важности признаков модели позваоляет сделать следующие наблюдения:\n",
    "\n",
    "- самыми влиятельными признаками оказались: географическое расположение стартапа (континент), бинарный признак \"multidisciplinary\", который выделял те стартапы, которые обладали несколькими категориями, а также категориальная группа стартапа и количество раундов финанисрования;\n",
    "- вероятно, отдельные категории стартапов действительно дают модели больше уверенности в исходе судьбы стартапа, однако также значительная часть классов (групп) едва ли возволяет провести какую-либо дихотомию; \n",
    "- незначительно на предсказания влияют: сумма финансирования стартапа (прологарифмированная), а также бинарный признак, описывающий последовательность финансирования/открытия стартапа;\n",
    "- стартапы из Америки действительно являются более успешыми, а стартапы из Европы и Азии - наоборот - чаще проваливаются и закрываются;\n",
    "- время между первым и последним раундом финансирования тоже играют определенную роль. Увеличение временного зазора между двумя событиямим влияет на вероятность модели предсказать закрытие стартапа;\n",
    "- время между открытием стартапа и первыми инвестициями в него тоже играет не последнюю роль для модели. Можно заметить, что меньший срок ожидания первых инвестиций способствует большей уверенности в успех бизнеса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f936394-a6ab-4c46-b12d-c7de0729b74e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7be9ff-a203-4520-bde0-80e620656f86",
   "metadata": {},
   "source": [
    "# Итоговые предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc00d02-0b0d-4ab9-883d-91c7fd25167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_clf.predict(transformer_xgb.transform(df_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e70d9e-a873-40dc-ab1f-8aec6678c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'name': df_sampsub.name.values, 'status': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa65bc4-6d9b-4076-a12e-1f0c28e2c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77944e5b-02ae-48ce-9a64-09c0972c350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./datasets/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d21cb-39fb-4c1c-a9ad-c396aea7cb22",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNIVERSAL",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
